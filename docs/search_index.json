[["index.html", "COMP/STAT 112: Introduction to Data Science Welcome!", " COMP/STAT 112: Introduction to Data Science Welcome! Data icons created by Kiranshastry - Flaticon Note: This site is still in construction! This is the day-to-day course site for Introduction to Data Science (COMP/STAT 112) taught by Professor Brianna Heggeseth at Macalester College for Fall 2022. The activities here were developed by a variety of faculty in the MSCS Department at Macalester College. This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],["course-schedule.html", "Course Schedule", " Course Schedule The schedule below is a tentative outline of our plans for the semester. For each class period, please start by actively reviewing the associated Learning Goals, review/finish the daily activity (turn in by deadline), and watch/read the indicated videos/readings to supplement your understanding. Week 1 Date Activity Topic & Assignments Optional Readings/Videos 8/31 1 Intro to R, RStudio, and R Markdown Slides for Today Assignment 1 Due Tuesday, September 6 at 11:59pm Readings: Introduction to R Markdown, by Wickham and Grolemund Tidy Data, by Wickham Tidy Data (12.1, 12.2), by Wickham and Grolemund Quarto, a VERY new alternative to R Markdown Videos: Setting up for success in the course, by Lisa Lendway Introduction to RStudio, by Alicia Johnson Check version of R and RStudio, by Lisa Lendway RStudio tour, by Lisa Lendway R Markdown introduction, by Lisa Lendway 9/2 Friday Fun: Community Building Scavenger Hunt Finish Assignment 1 (due 9/6). Week 2 Date Activity Topic & Assignments Optional Readings/Videos 9/7 2 Introduction to Data Visualization Set up NY Times Subscription (Free to you through Macalester) Slides for Today Assignment 2 Due Tuesday, September 13 at 11:59pm Readings: Data visualization, by Wickham and Grolemund Layered grammar of graphics, by Wickham and Grolemund A grammar for graphics (Chp 3), by Baumer, Kaplan, and Horton Aesthetic mapping (Chp 2), by Wilke Visualizing distributions (Chp 7), by Wilke Videos: Intro to ggplot , by Lisa Lendway 9/9 Friday Fun: Tidy Tuesday Slides for Today Readings: Telling a Story (Chp 29), by Wilke Finish Assignment 2 (due 9/13). Week 3 Date Activity Topic & Assignments Optional Readings/Videos 9/12 3 Effective Viz Slides for Today Readings: Equity Awareness for Data Visualizations, by Urban Institute Telling a story (Chp 29), by Wilke 9/14 4 Bivariate Viz Slides for Today Assignment 3 Due Tuesday, September 20 at 11:59pm FYC Library Tutorial (only FYC Section) Due Friday, September 16 at 9am Pre-Class Activity (only FYC Section) Due Friday, September 16 at 9am Readings: Visualizing amounts (Chp 6), by Wilke Videos: ggplot demo, Lisa Lendway Common ggplot mistakes, Lisa Lendway 9/16 Friday Fun: Meet in Idea Lab (Section 1 & 2), Meet in Library 206 for Library Session (Section F1) Finish Assignment 3 (due 9/20) Week 4 Date Activity Topic & Assignments Optional Readings/Videos 9/19 5 Multivariate Viz Slides for Today Assignment 4 Due Sunday, September 25 at 11:59pm Readings: Visualize This (Chp 7), by Yau Videos: More ggplot, Lisa Lendway 9/21 6 Spatial Viz Slides for Today Assignment 5 Due Tuesday, September 27 at 11:59pm Readings: Visualize This (Chp 8), by Yau Spatial data visualization (Chp 17, intro and 17.1), by Baumer et al. Videos: Plotting data on a map with ggmap, Lisa Lendway Glamour of graphics, Will Chase (slides here 9/23 Friday Fun: Introduction to Iterative Viz Finish Assignment 4 (due 9/25) and Assignment 5 (due 9/27) "],["learning-goals.html", "Learning Goals General Skills Course Topics", " Learning Goals The goal of this course is for you to gain confidence in carrying out the entire data science pipeline, from research question formulation, to data collection/scraping, to wrangling, to modeling, to visualization, to presentation and communication Specific course topics and general skills are listed below. General Skills Data Communication In written and oral formats: Inform and justify data cleaning and analysis process and the resulting conclusions with clear, organized, logical, and compelling details that adapt to the background, values, and motivations of the audience and context in which communication occurs. Collaborative Learning Understand and demonstrate characteristics of effective collaboration (team roles, interpersonal communication, self-reflection, awareness of social dynamics, advocating for yourself and others). Develop a common purpose and agreement on goals. Be able to contribute questions or concerns in a respectful way. Share and contribute to the group’s learning in an equitable manner. Develop a familiarity and comfort in using collaboration tools such as Git and Github. Course Topics Specific learning objectives for our course topics are listed below. Use these to guide your synthesis of course material for specific topics. Note that the topics are covered in the order of the data science pipeline, not the order in which we will cover them in class. Foundation Intro to R, RStudio, and R Markdown Download and install the necessary tools (R, RStudio) Develop comfort in navigating the tools in RStudio Develop comfort in writing and knitting a R Markdown file Identify the characteristics of tidy data Use R code: as a calculator and to explore tidy data Data Acquisition Data Import and Basic Cleaning Be able to find an existing data set to import into R Be able to import data of a variety of file types into R Understand and implement the data cleaning process to make values consistent Understand the implications of different ways of dealing with missing values with replace_na and drop_na Data Wrangling Six Main Wrangling Verbs Understand and be able to use the following verbs appropriate: select, mutate, filter, arrange, summarize, group_by Develop working knowledge of working with dates and lubridate functions Reshaping Data Understand the difference between wide and long data format and distinguish the case (unit of observation) for a given data set Be able to use pivot_wider and pivot_longer in the tidyr package Joining Data Understand the concept of keys and variables that uniquely identify rows or cases Understand the different types of joins, different ways of combining two data frames together Be able to use mutating joins: left_join, inner_join and full_join in the dplyr package Be able to use filtering joins: semi_join, anti_join in the dplyr package Categorical Variables as Factors Understand the difference between a variable stored as a character vs. a factor Be able to convert a character variable to a factor Be able to manipulate the order and values of a factor with the forcats package to improve summaries and visualizations. Wrangling Text using Regular Expression Be able to work with strings of text data Use regular expressions to search and replace, detect patterns, locate patterns, extract patterns, and separate text with the stringr package. Mini-Project Apply data wrangling and visualization skills to a new data set Be able to tell a story about data through visualization Data Visualization The learning goals may be adjusted before we start the material of this section. Introduction to Data Visualization Understand the Grammar of Graphics Use ggplot2 functions to create basic layers of graphics Understand the different basic univariate visualizations for categorical and quantiative variables Effective Visualization Understand and apply the guiding principles of effective visualizations Bivariate Identify appropriate types of bivariate visualizations, depending on the type of variables (categorical, quantitative) Create basic bivariate visualizations based on real data with ggplot2 functions Multivariate Understand how we can use additional aesthetics such as color and size to incorporate a third (or more variables) to a bivariate plot with ggplot2 functions Be able to with creating and interpreting heat maps and star plots, which allow you to look for patterns in variation in many variables. Spatial Plot data points on top of a map using the ggmap() function along with ggplot2 functions Create choropleth maps using geom_map() Add points and other ggplot2 features to a map created from geom_map() Understand the basics of creating a map using leaflet, including adding points and choropleths to a base map Data Modeling The learning goals may be adjusted before we start the material of this section. EDA Understand the first steps that should be taken when you encounter a new data set Develop comfort in knowing how to explore data to understand it Develop comfort in formulating research questions "],["intro-to-r-rstudio-and-r-markdown.html", "Topic 1 Intro to R, RStudio, and R Markdown Learning Goals Getting Started in RStudio R Markdown and Reproducible Research Practice Appendix: R Functions", " Topic 1 Intro to R, RStudio, and R Markdown Learning Goals Download and install the necessary tools (R, RStudio) Develop comfort in navigating the tools in RStudio Develop comfort in writing and knitting a R Markdown file Identify the characteristics of tidy data Use R code: as a calculator and to explore tidy data Getting Started in RStudio As you might guess from the name, “Data Science” requires data. Working with modern (large, messy) data sets requires statistical software. We’ll exclusively use RStudio. Why? it’s free it’s open source (the code is free &amp; anybody can contribute to it) it has a huge online community (which is helpful for when you get stuck) it’s one of the industry standards it can be used to create reproducible and lovely documents (In fact, the course materials that you’re currently reading were constructed entirely within RStudio!) Download R &amp; RStudio To get started, take the following two steps in the given order. Even if you already have R/RStudio, make sure to update to the most recent versions. Download and install the R statistical software at https://mirror.las.iastate.edu/CRAN/ Download and install the FREE version of RStudio at https://www.rstudio.com/products/rstudio/download/#download If you are having issues with downloading, log on to https://rstudio.macalester.edu/ (use Mac credentials) to use the RStudio server. What’s the difference between R and RStudio? Mainly, RStudio requires R – thus it does everything R does and more. We will be using RStudio exclusively. A quick tour of RStudio Open RStudio! You should see four panes, each serving a different purpose: Figure 1.1: RStudio Interface This short video tour of RStudio summarizes some basic features of the console. Exercise 1.1 (Warm Up) Use RStudio as a simple calculator to do the following: Perform a simple calculation: calculate 90/3. RStudio has built-in functions to which we supply the necessary arguments: function(arguments). Use the built-in function sqrt to calculate the square root of 25. Use the built-in function rep to repeat the number “5” eight times. Use the seq function to create the vector (0, 3, 6, 9, 12). (The video doesnt cover this!) Create a new vector by concatenating three repetitions of the vector from the previous part. Solution 90/3 ## [1] 30 sqrt(25) ## [1] 5 rep(5, times = 8) ## [1] 5 5 5 5 5 5 5 5 seq(0, 12, by = 3) ## [1] 0 3 6 9 12 rep(seq(0, 12, by = 3), times = 3) ## [1] 0 3 6 9 12 0 3 6 9 12 0 3 6 9 12 rep(seq(0, 12, by = 3), each = 3) #notice the difference between times and each ## [1] 0 0 0 3 3 3 6 6 6 9 9 9 12 12 12 Exercise 1.2 (Assignment) We often want to store our output for later use (why?). The basic idea in RStudio: `name &lt;- output` Copy and paste the following code into the console, line by line. NOTE: RStudio ignores any content after the #. Thus we use this to ‘comment’ and organize our code. #type square_3 square_3 #calculate 3 squared 3^2 #store this as &quot;square_3&quot; square_3 &lt;- 3^2 #type square_3 again! square_3 #do some math with square_3 square_3 + 2 Data Not only does “Data Science” require statistical software, it requires DATA! Consider the Google definition: Figure 1.2: A datum. With this definition in mind, which of the following are examples of data? tables ## family father mother sex height nkids ## 1 1 78.5 67.0 M 73.2 4 ## 2 1 78.5 67.0 F 69.2 4 ## 3 1 78.5 67.0 F 69.0 4 ## 4 1 78.5 67.0 F 69.0 4 ## 5 2 75.5 66.5 M 73.5 4 ## 6 2 75.5 66.5 M 72.5 4 photo video text / tweets We’ll mostly work with data that look like this: ## family father mother sex height nkids ## 1 1 78.5 67.0 M 73.2 4 ## 2 1 78.5 67.0 F 69.2 4 ## 3 1 78.5 67.0 F 69.0 4 ## 4 1 78.5 67.0 F 69.0 4 ## 5 2 75.5 66.5 M 73.5 4 ## 6 2 75.5 66.5 M 72.5 4 This isn’t as restrictive as it seems. We can convert the above signals: photos, videos, and text to a data table format! Tidy Data Example: After a scandal among FIFA officials, fivethirtyeight.com posted an analysis of FIFA viewership, “How to Break FIFA”. Here’s a snapshot of the data used in this article: country confederation population_share tv_audience_share gdp_weighted_share United States CONCACAF 4.5 4.3 11.3 Japan AFC 1.9 4.9 9.1 China AFC 19.5 14.8 7.3 Germany UEFA 1.2 2.9 6.3 Brazil CONMEBOL 2.8 7.1 5.4 United Kingdom UEFA 0.9 2.1 4.2 Italy UEFA 0.9 2.1 4.0 France UEFA 0.9 2.0 4.0 Russia UEFA 2.1 3.1 3.5 Spain UEFA 0.7 1.8 3.1 The data table above is in tidy format. Tidy data tables have three key features: Each row represents a unit of observation (also referred to as a case). Each column represents a variable (ie. an attribute of the cases that can vary from case to case). Each variable is one of two types: quantitative = numerical categorical = discrete possibilities/categories Each entry contains a single data value; no analysis, summaries, footnotes, comments, etc., and only one value per cell Tidy Data: Art by Allison Horst Exercise 1.3 (Units of Observation and Variables) Consider the following in a group: What are the units of observation in the FIFA data? What are the variables? Which are quantitative? Which are categorical? Are these tidy data? Solution A FIFA member country country name, soccer or football confederation, country’s share of global population (percentage), country’s share of global world cup TV Audience (percentage), country’s GDP-weighted audience share (percentage) Yes Exercise 1.4 (Tidy vs. Untidy) Check out the following data. Explain to each other why they are untidy and how we can tidy them. Data 1: FIFA country confederation population share tv_share United States CONCACAF i don’t know* 4.3% *look up later Japan AFC 1.9 4.9% China AFC 19.5 14.8% total=24% Data 2: Gapminder life expectancies by country country 1952 1957 1962 Asia Afghanistan 28.8 30.3 32.0 Bahrain 50.9 53.8 56.9 Africa Algeria 43.0 45.7 48.3 Solution There are notes such as “I don’t know” and “look up later” in columns with numeric values; the last row with the total is a summary. We could remove the text notes, replace it with the value if known, and remove the last row with the total summary. The first column does not have a row name. It should be continent. Additionally, Bahrain needs a value for the continent. Data Basics in RStudio For now, we’ll focus on tidy data. In a couple of weeks, you’ll learn how to turn untidy data into tidy data. Exercise 1.5 (Importing Package Data) The first step to working with data in RStudio is getting it in there! How we do this depends on its format (eg: Excel spreadsheet, csv file, txt file) and storage locations (eg: online, within Wiki, desktop). Luckily for us, the fifa_audience data are stored in the fivethirtyeight RStudio package. Copy and paste the following code into the Console and press Enter. #download the data and information in the fivethirtyeight package (we only need to do this once) install.packages(&#39;fivethirtyeight&#39;) #load the fivethirtyeight package library(fivethirtyeight) #load the fifa data data(&quot;fifa_audience&quot;) #store this under a shorter, easier name fifa &lt;- fifa_audience Exercise 1.6 (Examining Data Structures) Before we can analyze our data, we must understand its structure. Try out the following functions (copy and paste into the Console). For each, make a note that describes its action. #(what does View do?) View(fifa) #(what does head do?) head(fifa) #(what does dim do?) dim(fifa) #(what does names do?) names(fifa) Solution #View() opens up a new tab with a spreadsheet preview of the data to visually explore the data. It is commented out in the Rmarkdown file because this is an interactive feature #View(fifa) #head() gives the first 6 (default number) rows of a data set head(fifa) ## # A tibble: 6 × 5 ## country confederation population_share tv_audience_share gdp_weighted_share ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 United States CONCACAF 4.5 4.3 11.3 ## 2 Japan AFC 1.9 4.9 9.1 ## 3 China AFC 19.5 14.8 7.3 ## 4 Germany UEFA 1.2 2.9 6.3 ## 5 Brazil CONMEBOL 2.8 7.1 5.4 ## 6 United Kingdom UEFA 0.9 2.1 4.2 #dim() gives the number of rows and number of columns dim(fifa) ## [1] 191 5 #names() gives the names of the columns/variables names(fifa) ## [1] &quot;country&quot; &quot;confederation&quot; &quot;population_share&quot; &quot;tv_audience_share&quot; ## [5] &quot;gdp_weighted_share&quot; Exercise 1.7 (Codebooks) Data are also only useful if we know what they measure! The fifa data table is tidy; it doesn’t have any helpful notes in the data itself. Rather, information about the data is stored in a separate codebook. Codebooks can be stored in many ways (eg: Google docs, word docs, etc). Here the authors have made their codebook available in RStudio (under the original fifa_audience name). Check it out (run the following code in the console): ?fifa_audience What does population_share measure? What are the units of population_share? Solution Country’s share of global population Percentage between 0 and 100   Exercise 1.8 (Examining a Single Variable) Consider the following: We might want to access and focus on a single variable. To this end, we can use the $ notation (see below). What are the values of tv_audience_share? Of confederation? Is it easy to figure out? fifa$tv_audience_share fifa$confederation It’s important to understand the format/class of each variable (quantitative, categorical, date, etc) in both its meaning and its structure within RStudio: class(fifa$tv_audience_share) class(fifa$confederation) If a variable is categorical (in factor format), we can determine its levels / category labels. What are the value of confederation? levels(fifa$confederation) #it is in character format levels(factor(fifa$confederation)) #we can convert to factor format R Markdown and Reproducible Research Reproducible research is the idea that data analyses, and more generally, scientific claims, are published with their data and software code so that others may verify the findings and build upon them. - Reproducible Research, Coursera Useful Resources: R Markdown Quick Tour R Markdown Cheatsheet R Markdown Reference Guide Research often makes claims that are difficult to verify. A recent study of published psychology articles found that less than half of published claims could be reproduced. One of the most common reasons claims cannot be reproduced is confusion about data analysis. It may be unclear exactly how data was prepared and analyzed, or there may be a mistake in the analysis. In this course we will use an innovative format called R Markdown that dramatically increases the transparency of data analysis. R Markdown interleaves data, R code, graphs, tables, and text, packaging them into an easily publishable format. To use R Markdown, you will write an R Markdown formatted file in RStudio and then ask RStudio to knit it into an HTML document (or occasionally a PDF or MS Word document). Exercise 1.9 (Deduce the R Markdown Format) Look at this Sample RMarkdown and the HTML webpage it creates. Consider the following and discuss: How are bullets, italics, and section headers represented in the R Markdown file? How does R code appear in the R Markdown file? In the HTML webpage, do you see the R code, the output of the R code, or both? Solution Bullets are represented with * and + Italics are represented with * before and after a word or phrase Section headers are represented with # R code chunks are between 3 tick marks at the beginning and end; it is R code if there is an r in curly braces If echo=FALSE in curly braces, the code is not shown. Otherwise, both code and output are shown by default.   Now take a look at the R Markdown cheatsheet. Look up the R Markdown features from the previous question on the cheatsheet. There’s a great deal more information there. Practice Complete the following. If you get stuck along the way, refer to the R Markdown cheatsheet linked above, search the web for answers, and/or ask for help! Exercise 1.10 (Your First R Markdown File) Create a new R Markdown about your favorite food. Create a new file in RStudio (File -&gt; New File -&gt; R Markdown) with a Title of First_Markdown. Save it to a new folder on your Desktop called COMP_STAT_112; within that new folder, create another new folder called Day_01. Make sure you can compile/render (Knit) the Markdown into a webpage (html file). Add a new line between title and output that reads: author: Your Name. Create a very brief essay about your favorite food. Make sure to include: A picture from the web A bullet list A numbered list Compile (Knit) the document into an html file. Exercise 1.11 (New Data!) There’s a data set named comic_characters in the fivethirtyeightdata package. Install the package by running the following in the Console: install.packages(&#39;fivethirtyeightdata&#39;, repos = &#39;https://fivethirtyeightdata.github.io/drat/&#39;, type = &#39;source&#39;) Check out the codebook (hint: use ?) to understand what these data measure. Then add a second section to your R Markdown file, and then use code chunks and R commands to perform/answer the following tasks/questions: Load the data. What are the units of observation? How many observations are there? In a new code chunk, print out the first 12 rows of the data set. Get a list of all variable names. What’s the class of the date variable? List all of the unique entries in the gsm variable (no need to include NA). Compile the document into an html file. Appendix: R Functions R as a calculator Function/Operator Action Example / Division 90/30 * Multiplication 2*5 + Addition 1+1 - Subtraction 1-1 ^ Exponent/Power to 3^2 sqrt(x) Square root sqrt(25) R Basics Function/Operator Action Example install.packages('packagename') Download a R package (function, data, etc.) from repository install.packages('fivethirtyeight') library(packagename) Access a downloaded R package library(fivethirtyeight) ?function_object_name Opens the help/documentation for the function or object ?seq rep(x, times, each) Repeat x a # times rep(5,8) seq(from,to,by) Sequence generation 2*5 name &lt;- value_output Assign value or output to a name squared_3 &lt;- 3^2 View(x) Open spreadsheet viewer of dataset View(fifa_audience) head(x) Print the first 6 rows of a dataset head(fifa_audience) dim(x) Print the dimensions (number of rows and columns) of a dataset dim(fifa_audience) names(x) Print the names of the variables in a dataset names(fifa_audience) $ Used to access one variable in a data set based on its name fifa_audience$confederation class(x) Print the class types argument or input class(fifa_audience$confederation) factor(x) Converts the argument or input to a factor class type (categorical variable) factor(fifa_audience$confederation) levels(x) Prints the unique categories of a factor levels(factor(fifa_audience$confederation)) "],["intro-to-data-visualization.html", "Topic 2 Intro to Data Visualization Learning Goals Benefits of Visualizations Glyphs Data Visualization Workflow + ggplot Additional exercises Appendix: R Functions", " Topic 2 Intro to Data Visualization Learning Goals Understand the Grammar of Graphics Use ggplot2 to create basic layers of graphics Understand the different basic univariate visualizations for categorical and quantitative variables You can download a template .Rmd of this activity here. Put this in a new folder called Day_02 in your folder for COMP_STAT_112. Benefits of Visualizations Visualizations help us understand what we’re working with: What are the scales of our variables? Are there any outliers, i.e. unusual cases? What are the patterns among our variables? This understanding will inform our next steps: What method of analysis / model is appropriate? Once our analysis is complete, visualizations are a powerful way to communicate our findings and tell a story. Glyphs In its original sense, in archaeology, a glyph is a carved symbol. Heiroglyph Mayan glyph Data Glyph A data glyph is also a mark, e.g. The features of a data glyph encodes the value of variables. Some are very simple, e.g. a dot: Some combine different elements, e.g. a pointrange: Some are complicated, e.g. a dotplot: Components of Graphics Figure 2.1: Blood pressure readings from a random subset of the NHANES data set. frame: The position scale describing how data are mapped to x and y glyph: The basic graphical unit that represents one case. other terms used include mark and symbol. aesthetic: a visual property of a glyph such as position, size, shape, color, etc. may be mapped based on data values: smoker -&gt; color may be set to particular non-data related values: color is black facet: a subplot that shows one subset of the data rather than represent sex by shape, we could split into two subplots scale: A mapping that translates data values into aesthetics. example: never-&gt; pink; former-&gt; aqua; current-&gt; green guide: An indication for the human viewer of the scale. This allows the viewer to translate aesthetics back into data values. examples: x- and y-axes, various sorts of legends Eye Training for the Layered Grammar of Graphics Exercise 2.1 (Basic questions to ask of a data graphic) For your assigned graphic, discuss the following seven questions with your partner(s): What variables constitute the frame? What glyphs are used? What are the aesthetics for those glyphs? Which variable is mapped to each aesthetic? Which variable, if any, is used for faceting? Which scales are displayed with a guide? What raw data would be required for this plot, and what form should it be in? Here are the graphics examples, all taken from the New York Times website: Admissions gap Medicare hospital charges Football conferences Housing prices Baseball pitching Phillips curve School mathematics ratings Corporate taxes Glyph-Ready Data Note the mapping of data to aesthetics for Figure 2.1: sbp [Systolic Blood Pressure] -&gt; x dbp [Diastolic Blood Pressure] -&gt; y smoker -&gt; color sex -&gt; shape Glyph-ready data has this form: There is one row for each glyph to be drawn. The variables in that row are mapped to aesthetics of the glyph (including position). Table 2.1: A subset of the NHANES data set. sbp dbp sex smoker 112 55 male former 144 84 male never 143 84 female never 110 62 female never 121 72 female never 129 60 female never Data Visualization Workflow + ggplot Layers – Building up Complex Plots Using the ggplot2 package, we can create graphics by building up layers, each of which may have its own data, glyphs, aesthetic mapping, etc. As an example, let’s peel back the layers used to create Figure 2.1. The first layer just identifies the data set. It sets up a blank canvas, but does not actually plot anything: ggplot(data = Tmp) Next, we add a geometry layer to identify the mapping of data to aesthetics for each of the glyphs: ggplot(data = Tmp) + geom_point(mapping = aes(x = sbp, y = dbp, shape = sex, color = smoker), size = 5, alpha = .8) Next, we can add some axes labels as guides: ggplot(data = Tmp) + geom_point(mapping = aes(x = sbp, y = dbp, shape = sex, color = smoker), size = 5, alpha = .8) + xlab(&quot;Systolic BP&quot;) + ylab(&quot;Diastolic BP&quot;) And, finally, we can change the scale of the color used for smoker status: ggplot(data = Tmp) + geom_point(mapping = aes(x = sbp, y = dbp, shape = sex, color = smoker), size = 5, alpha = .8) + xlab(&quot;Systolic BP&quot;) + ylab(&quot;Diastolic BP&quot;) + scale_color_manual(values = c(&quot;#F8766D&quot;, &quot;#00BFC4&quot;, &quot;#00BA38&quot;)) If instead we wanted to facet into columns based on smoker status, we could add another layer for that: ggplot(data = Tmp) + geom_point(mapping = aes(x = sbp, y = dbp, shape = sex, color = smoker), size = 5, alpha = .8) + xlab(&quot;Systolic BP&quot;) + ylab(&quot;Diastolic BP&quot;) + scale_color_manual(values = c(&quot;#F8766D&quot;, &quot;#00BFC4&quot;, &quot;#00BA38&quot;)) + facet_grid(. ~ smoker) For more information on all of the different types of layers we can add to graphics, see the ggplot2 reference page and the data visualization with ggplot2 cheat sheet. Getting Started There’s no end to the number and type of visualizations you could make. Thus the process can feel overwhelming. FlowingData makes good recommendations for data viz workflow: Ask the data questions. Simple research questions will guide the types of visualizations that you should construct. Start with the basics and work incrementally. Before constructing complicated or multivariate or interactive graphics, start with simple visualizations. An understanding of the simple patterns provides a foundation upon which to build more advanced analyses and visualizations. This incremental process works particularly well with the layered grammar of graphics in ggplot. Focus. Reporting a large number of visualizations can overwhelm the audience and obscure your conclusions. Instead, pick out a focused yet comprehensive set of visualizations. Here is an example of one dataset visualized 25 different ways, each with a different focus and interpretation, and what can happen if you let the data ramble on without a focus. In this course we’ll largely construct visualizations using the ggplot function in RStudio. Though the ggplot learning curve can be steep, its “grammar” is intuitive and generalizable once mastered. The ggplot plotting function is stored in the ggplot2 package: library(ggplot2) The best way to learn about ggplot is to just play around. Focus on the patterns and potential of their application. It will be helpful to have the RStudio Data Visualization cheat sheet handy as you complete this activity. An Example The “Bechdel test”, named after cartoonist Alison Bechdel, tests whether movies meet the following criteria: There are \\(\\ge\\) 2 (named) female characters; these women talk to each other… about something other than a man. In the fivethirtyeight.com article “The Dollar-And-Cents Case Against Hollywood’s Exclusion of Women”, the authors analyze which Hollywood movies do/don’t pass the test. Their data are available in the fivethirtyeight package: library(fivethirtyeight) data(bechdel) head(bechdel) year imdb title clean_test binary budget_2013 domgross_2013 intgross_2013 2013 tt1711425 21 &amp; Over notalk FAIL 13000000 25682380 42195766 2012 tt1343727 Dredd 3D ok PASS 45658735 13611086 41467257 2013 tt2024544 12 Years a Slave notalk FAIL 20000000 53107035 158607035 2013 tt1272878 2 Guns notalk FAIL 61000000 75612460 132493015 2013 tt0453562 42 men FAIL 40000000 95020213 95020213 2013 tt1335975 47 Ronin men FAIL 225000000 38362475 145803842 Exercise 2.2 Before diving into any visualizations of these data, we first must understand its structure and contents. Discuss the following: What are the units of observation and how many units are in this sample? What are the levels of the clean_test and binary categorical variables? Check out the codebook for bechdel (?bechdel). What’s the difference between domgross_2013 and domgross? Solution #units of observation are movies; there are 1794 movies in this sample dim(bechdel) ## [1] 1794 15 #clean_test has values of &quot;nowomen&quot;, &quot;notalk&quot;, &quot;men&quot;, &quot;dubious&quot;, &quot;ok&quot; #View(bchedel) and look at values or summarize like below table(bechdel$clean_test) ## ## nowomen notalk men dubious ok ## 141 514 194 142 803 levels(bechdel$clean_test) ## [1] &quot;nowomen&quot; &quot;notalk&quot; &quot;men&quot; &quot;dubious&quot; &quot;ok&quot; #binary has values of PASS or FAIL table(bechdel$binary) ## ## FAIL PASS ## 991 803 levels(factor(bechdel$binary)) ## [1] &quot;FAIL&quot; &quot;PASS&quot; # domgross_2013 is the domestic gross in US dollars but it is inflation adjusted with respect to 2013 #?bechdel Exercise 2.3 We’ll consider univariate visualizations of the clean_test and budget_2013 variables. Discuss the following: What features would we like a visualization of the categorical clean_test variable to capture? What features would we like a visualization of the quantitative budget_2013 variable to capture? Solution capture the frequency of each way a movie can fail or pass the Bechdel test capture the typical budget as well as how much variation there is across movies and if there are any outliers Categorical univariate visualization We begin by stating a clear research question: Among the movies in our sample, what fraction pass the Bechdel test? Among those that fail the test, in which way do they fail (e.g., there are no women, there are women but they only talk about men,…)? To answer the above research question, we can explore the categorical clean_test variable. A table provides a simple summary of the number of movies that fall into each clean_test category: table(bechdel$clean_test) ## ## nowomen notalk men dubious ok ## 141 514 194 142 803 Exercise 2.4 Examine the table of clean_test data, and try to interpret it. What insights does it provide about the original research question? Solution Among the categories, the “ok” category was most frequent, meaning that 803 of the 1794 movies in the sample passed the Bechdel Test. However, among those 991 movies that did not pass the test, most of them (514 of them) did not pass because the women did not talk. Because clean_test is a categorical variable, a bar chart provides an appropriate visualization of this table. In examining the bar chart, keep your eyes on the following. variability: Are cases evenly spread out among the categories or are some categories more common than others? contextual implications: In the context of your research, what do you learn from the bar chart? How would you describe your findings to a broad audience? Exercise 2.5 Try out the code below that builds up from a simple to a customized bar chart. At each step determine how each piece of code contributes to the plot. # plot 1: set up a plotting frame (a blank canvas) ggplot(bechdel, aes(x = clean_test)) # plot 2: what changed / how did we change it? ggplot(bechdel, aes(x = clean_test)) + geom_bar() # plot 3: what changed / how did we change it? ggplot(bechdel, aes(x = clean_test)) + geom_bar() + labs(x = &quot;Outcome of Bechdel Test&quot;, y = &quot;Number of movies&quot;) # plot 4: what changed / how did we change it? ggplot(bechdel, aes(x = clean_test)) + geom_bar(color = &quot;purple&quot;) + labs(x = &quot;Outcome of Bechdel Test&quot;, y = &quot;Number of movies&quot;) # plot 5: what changed / how did we change it? ggplot(bechdel, aes(x = clean_test)) + geom_bar(fill = &quot;purple&quot;) + labs(x = &quot;Outcome of Bechdel Test&quot;, y = &quot;Number of movies&quot;) Solution # plot 1: set up a plotting frame (a blank canvas) ggplot(bechdel, aes(x = clean_test)) # plot 2: Added bars that reflect the count or frequency of the movies within each category ggplot(bechdel, aes(x = clean_test)) + geom_bar() # plot 3: Added/changed the text labels for the x and y axes ggplot(bechdel, aes(x = clean_test)) + geom_bar() + labs(x = &quot;Outcome of Bechdel Test&quot;, y = &quot;Number of movies&quot;) # plot 4: Changed the outline color of the bars to purple ggplot(bechdel, aes(x = clean_test)) + geom_bar(color = &quot;purple&quot;) + labs(x = &quot;Outcome of Bechdel Test&quot;, y = &quot;Number of movies&quot;) # plot 5: Changed the fill color of the bars to purple ggplot(bechdel, aes(x = clean_test)) + geom_bar(fill = &quot;purple&quot;) + labs(x = &quot;Outcome of Bechdel Test&quot;, y = &quot;Number of movies&quot;) Exercise 2.6 Summarize the visualization: what did you learn about the distribution of the clean_test variable? Solution Among the categories, the “ok” category was most frequent. However, among those movies that did not pass the test, most of them did not pass because the women in the movie did not talk. Exercise 2.7 Let’s return to our research question: What percent of movies in the sample pass the Bechdel test? Among those that fail the test, in which way do they fail? Solution table(bechdel$binary) ## ## FAIL PASS ## 991 803 803/(991 + 803) ## [1] 0.4476031 table(bechdel$clean_test)[1:4]/991 ## ## nowomen notalk men dubious ## 0.1422805 0.5186680 0.1957619 0.1432896 Quantitative univariate visualization To motivate quantitative visualizations, consider a second research question Among the movies in our sample, what’s the range of budgets? What’s the typical budget? The largest/smallest? We can answer the above research question by exploring the quantitative budget_2013 variable. Quantitative variables require different summary tools than categorical variables. We’ll explore two methods for graphing quantitative variables: histograms and density plots. Both of these has strengths/weaknesses in helping us visualize the distribution of observed values. In their examination, keep your eyes on the following. center: Where’s the center of the distribution? What’s a typical value of the variable? variability: How spread out are the values? A lot or a little? shape: How are values distributed along the observed range? Is the distribution symmetric, right-skewed, left-skewed, bi-modal, or uniform (flat)? outliers: Are there any outliers, ie. values that are unusually large/small relative to the bulk of other values? contextual implications: Interpret these features in the context of your research. How would you describe your findings to a broad audience? Histograms Histograms are constructed by (1) dividing up the observed range of the variable into ‘bins’ of equal width; and (2) counting up the number of cases that fall into each bin. Exercise 2.8 Try out the code below. At each step determine how each piece of code contributes to the plot. # plot 1: set up a plotting frame ggplot(bechdel, aes(x = budget_2013)) # plot 2: what changed / how did we change it? ggplot(bechdel, aes(x = budget_2013)) + geom_histogram() # plot 3: what changed / how did we change it? ggplot(bechdel, aes(x = budget_2013)) + geom_histogram() + labs(x = &quot;Budget ($)&quot;, y = &quot;Number of movies&quot;) # plot 4: what changed / how did we change it? ggplot(bechdel, aes(x = budget_2013)) + geom_histogram(color = &quot;white&quot;) + labs(x = &quot;Budget ($)&quot;, y = &quot;Number of movies&quot;) # plot 5: what changed / how did we change it? ggplot(bechdel, aes(x = budget_2013)) + geom_histogram(fill = &quot;white&quot;) + labs(x = &quot;Budget ($)&quot;, y = &quot;Number of movies&quot;) # plot 6: what changed / how did we change it? ggplot(bechdel, aes(x = budget_2013)) + geom_histogram(color = &quot;white&quot;, binwidth = 500000) + labs(x = &quot;Budget ($)&quot;, y = &quot;Number of movies&quot;) # plot 7: what changed / how did we change it? ggplot(bechdel, aes(x = budget_2013)) + geom_histogram(color = &quot;white&quot;, binwidth = 200000000) + labs(x = &quot;Budget ($)&quot;, y = &quot;Number of movies&quot;) Solution # plot 1: set up a plotting frame ggplot(bechdel, aes(x = budget_2013)) # plot 2: Added bars the represent the count of movies within budget intervals ggplot(bechdel, aes(x = budget_2013)) + geom_histogram() # plot 3: Updated the text on the x and y axis labels ggplot(bechdel, aes(x = budget_2013)) + geom_histogram() + labs(x = &quot;Budget ($)&quot;, y = &quot;Number of movies&quot;) # plot 4: The outline of the bars is now white ggplot(bechdel, aes(x = budget_2013)) + geom_histogram(color = &quot;white&quot;) + labs(x = &quot;Budget ($)&quot;, y = &quot;Number of movies&quot;) # plot 5: The fill of the bars is now white ggplot(bechdel, aes(x = budget_2013)) + geom_histogram(fill = &quot;white&quot;) + labs(x = &quot;Budget ($)&quot;, y = &quot;Number of movies&quot;) # plot 6: The width of the interval or bin is decreased to $500,000 ggplot(bechdel, aes(x = budget_2013)) + geom_histogram(color = &quot;white&quot;, binwidth = 500000) + labs(x = &quot;Budget ($)&quot;, y = &quot;Number of movies&quot;) # plot 7: The width of the interval or bin is increased to $200,000,000 ggplot(bechdel, aes(x = budget_2013)) + geom_histogram(color = &quot;white&quot;, binwidth = 200000000) + labs(x = &quot;Budget ($)&quot;, y = &quot;Number of movies&quot;) Exercise 2.9 Summarize the visualizations. Describe the problem in choosing a bin width that’s not too wide and not too narrow, but just right. What did you learn about the distribution of the budget_2013 variable? Why does adding color = \"white\" improve the visualization? Solution If the intervals (bars, bins) are too wide, then we lose information about the variation in the budget. Take it to the extreme with just 1 bar with the bar ranging from the minimum to the maximum. If the intervals are too small, then we have the frequency of the bars go up and down quite a bit. We might say that the shape of the bars isn’t very smooth. Most of the movies have small budgets; the majority less of budgets are less than $100,000,000 (in 2013 dollars) but there are some movies with upwards of $300,000,000 (in 2013 dollars). Adding the white outline to the bars adds contrast and helps the viewer see where each bar starts and ends. Density plots Density plots are essentially smooth versions of the histogram. Instead of sorting cases into discrete bins, the “density” of cases is calculated across the entire range of values. The greater the number of cases, the greater the density! The density is then scaled so that the area under the density curve always equals 1 and the area under any fraction of the curve represents the fraction of cases that lie in that range. Exercise 2.10 Try the following code and assess what each line does. # plot 1: set up the plotting frame ggplot(bechdel, aes(x = budget_2013)) # plot 2: what changed / how did we change it? ggplot(bechdel, aes(x = budget_2013)) + geom_density() # plot 3: what changed / how did we change it? ggplot(bechdel, aes(x = budget_2013)) + geom_density() + labs(x = &quot;Budget ($)&quot;) # plot 4: what changed / how did we change it? ggplot(bechdel, aes(x = budget_2013)) + geom_density(color = &quot;red&quot;) + labs(x = &quot;Budget ($)&quot;) # plot 5: what changed / how did we change it? ggplot(bechdel, aes(x = budget_2013)) + geom_density(fill = &quot;red&quot;) + labs(x = &quot;Budget ($)&quot;) Solution # plot 1: set up the plotting frame ggplot(bechdel, aes(x = budget_2013)) # plot 2: add a smooth curve (shape of the histogram) ggplot(bechdel, aes(x = budget_2013)) + geom_density() # plot 3: updated the x axis label ggplot(bechdel, aes(x = budget_2013)) + geom_density() + labs(x = &quot;Budget ($)&quot;) # plot 4: changed the color of the curve to red ggplot(bechdel, aes(x = budget_2013)) + geom_density(color = &quot;red&quot;) + labs(x = &quot;Budget ($)&quot;) # plot 5: filled the area under the curve to be red ggplot(bechdel, aes(x = budget_2013)) + geom_density(fill = &quot;red&quot;) + labs(x = &quot;Budget ($)&quot;)   Exercise 2.11 The histogram and density plot both allow us to visualize the distribution of a quantitative variable. What are the pros/cons of each? Discuss. Additional exercises Exercise 2.12 In July 2016, fivethirtyeight.com published the article “Hip-Hop is Turning on Donald Trump””. You can find the supporting data table hiphop_cand_lyrics in the fivethirtyeight package: library(fivethirtyeight) data(hiphop_cand_lyrics) What are the cases in this data set? Use RStudio functions to: summarize the number of cases in hiphop_cand_lyrics examine the first cases of hiphop_cand_lyrics list out the names of all variables in hiphop_cand_lyrics Exercise 2.13 Let’s start our investigation of hip hop data by asking “Who?”; that is, let’s identify patterns in which 2016 presidential candidates popped up in hip hop lyrics. Use an RStudio function to determine the category labels used for the candidate variable. Use table to construct a table of the number of cases that fall into each candidate category. Construct a single plot that allows you to investigate the prevalence of each candidate in hip hop. Make the following modifications: - change the axis labels - change the fill colors Summarize your findings about the 2016 candidates in hip hop. Exercise 2.14 Next, consider the release dates of the hip hop songs. Construct a histogram of the release dates with the following modifications: - change the fill color of the bins - change the bin width to a meaningful size Construct a density plot of the release dates with the following modifications: - change the fill color Summarize your findings about release date Exercise 2.15 No class will teach you everything you need to know about RStudio or programming in general. Thus, being able to find help online is an important skill. To this end, make a single visualization that incorporates the following modifications to your density plot from above. This will require a little Googling and/or use of the visualization cheat sheet. Add a title or caption. Add transparency to the fill color. Calculate the mean (ie. average) release date and median release date: mean(hiphop_cand_lyrics$album_release_date) median(hiphop_cand_lyrics$album_release_date) Add two vertical lines to your plot: one representing the mean and the other representing the median. Use two different colors and/or line types. Change the limits of the x-axis to range from 1980-2020. Appendix: R Functions Basic R functions Function/Operator Action Example table(x) Frequency count of categories in x table(bechdel$clean_test) mean(x) Average or mean of numeric values in x mean(bechdel$budget_2013) median(x) Median of numeric values in x median(bechdel$budget_2013) ggplot2 foundation functions Function/Operator Action Example ggplot(data) Create a blank canvas that can create a visualization based on data ggplot(data = bechdel) ggplot(data,aes()) Create a blank canvas that can create a visualization based on data with aesthetic mapping ggplot(data = bechdel, aes(x = budget_2013)) + geom_bar(aes(x)) Add a bar plot geom_bar(aes(x = clean_test)) + geom_point(aes(x,y)) Add a scatterplot geom_bar(aes(x = year,y=budget_2013)) + geom_histogram(aes(x)) Add a histogram geom_histogram(aes(x = budget_2013)) + geom_density(aes(x)) Add a density plot geom_density(aes(x = budget_2013)) more ggplot2 functions Function/Operator Action Example + xlab() Add an label for the x-axis xlab('X axis') + ylab() Add an label for the y-axis ylab('Y axis') + labs(x,y) Add labels for the x and y-axis labs(y = 'Y axis', x = 'X axis') + scale_color_manual() Set a color palette for the color aesthetic scale_color_manual(values = c('blue','red')) + facet_grid() Create subplots based on categorical variables, groupvar_along_yaxis ~ groupvar_along_xaxis + facet_grid(. ~ smoker) ggplot2 aesthetic mapping options Function/Operator Action Example x variable for x-axis aes(x = clean_test) y variable for y-axis aes(y = budget_2013) color variable for colors of points or strokes/outline aes(color = clean_test) fill variable for fill of bars or shapes aes(fill = clean_test) size variable for size shapes aes(size = budget_2013) shape variable for shape type aes(shape = clean_test) "],["effective-visualizations.html", "Topic 3 Effective Visualizations Learning Goals Effective Visualizations Exercises", " Topic 3 Effective Visualizations Learning Goals Understand and apply the guiding principles of effective visualizations You can download a template .Rmd of this activity here. Put the file in a Day_03 folder within your COMP_STAT_112 folder. Effective Visualizations Benefits of Visualizations Visualizations help us understand what we’re working with: What are the scales of our variables? Are there any outliers, i.e. unusual cases? What are the patterns among our variables? This understanding will inform our next steps: What method of analysis / model is appropriate? Once our analysis is complete, visualizations are a powerful way to communicate our findings and tell a story. Analysis of Graphics There is not one right way to visualize a data set. However, there are guiding principles that distinguish between “good” and “bad” graphics. One of the best ways to learn is by reading graphics and determining which ways of arranging thing are better or worse. So before jumping directly into theoretical principles, let’s try some critical analysis on specific examples. Exercise 3.1 For your assigned graphics or sets of graphics, identify the following: the story the graphic is aiming to communicate to the audience effective features of the graphic areas for improvement Figure 3.1: Source: http://viz.wtf/ Figure 3.2: Source: N. Yau, Visualize This, 2011, p. 223-225. Figure 3.3: Source: N. Yau, Visualize This, 2011, p. 242. Figure 3.4: Gun deaths. Figure 3.5: Source: N. Yau, Visualize This, 2011, p. 150. Figure 3.6: Source: C. N. Knaflic, Storytelling with Data, 2015, p. 142. Figure 3.7: Source: S. Few, Now You See It, 2009, p. 45. Figure 3.8: Climate change. Figure 3.9: Source: C. N. Knaflic, Storytelling with Data, 2015, p. 48. Figure 3.10: Diamond data visualizations from R for Data Science, 2017 Figure 3.11: Source: S. Few, Now You See It, 2009, p. 37. Figure 3.12: Source: N. Yau, Visualize This, 2011, p. 249. Figure 3.13: Source: S. Few, Now You See It, 2009, p. 61. Figure 3.14: Source: C. N. Knaflic, Storytelling with Data, 2015, p. 68. Figure 3.15: Source: C. N. Knaflic, Storytelling with Data, 2015, p. 81. Figure 3.16: Source: http://viz.wtf/ Figure 3.17: Source: A. Cairo, The Functional Art, 2013, p. 340. Figure 3.18: Source: N. Yau, Visualize This, 2011, p. 220. More examples: FlowingData: blog and Best visualizations of 2016 WTF Visualizations Properties of Effective Visualizations Storytelling / Context Remember … Graphics are designed by the human expert (you!) in order to reveal information that’s in the data. Your choices depend on what information you want to reveal and convey. So before you complete a graphic, you should clearly identify what story you want the graphic to tell to the audience, and double check that this story is being told.1 Here is a nice example from FiveThirtyEight where each chart tells a story in answer to a particular question about the [then] upcoming German election. Here is an interactive visualization that tells a story about gun violence. Another important contextual question to ask is whether the graphic is for an explanatory (explain why) or exploratory (discovering something new) analysis. Ethics Michael Correll of Tableau Research writes “Data visualizations have a potentially enormous influence on how data are used to make decisions across all areas of human endeavor.” in his article from 2018. Visualization operates at the intersection of science, communication, and data science &amp; statistics. There are professional standards of ethics in these fields of the power they hold over other people as it relates to making data-driven decisions. Correll describes three ethical challenges of visualization work: Visibility Make the invisible visible Visualize hidden labor Visualize hidden uncertainty Visualize hidden impacts Visualizations can be complex and one must consider the accessibility of the visualization to the audience. Managing complexity is, therefore, a virtue in design that can be in direct opposition with the desire to visualize the invisible. Privacy Collect data with empathy Encourage Small Data Anthropomorphize data Obfuscate data to protect privacy Restricting the type and amount of data that is collected has a direct impact on the quality and scope of the analyses hence obligation to provide context, and analytical power can, therefore, stand in direct opposition to the empathic collection of data. Power Challenge structures of power Support data due process. Act as data advocates. Pressure unethical analytical behavior. The goal of promoting truth and suppressing falsehood may require amplifying existing structures of expertise and power, and suppressing conflicts for the sake of rhetorical impact. At a minimum, you should always Present data in a way that avoids misleading the audience. Always include your data source. Doing so attributes credit for labor, provides credibility to your work, and provides context for your graphic. Design A basic principle is that a graphic is about comparison. Good graphics make it easy for people to perceive things that are similar and things that are different. Good graphics put the things to be compared “side-by-side,” that is, in perceptual proximity to one another. The following aesthetics are listed in roughly descending order of human ability to perceive and compare nearby objects:2 Position Length Angle Direction Shape (but only a very few different shapes) Area Volume Shade Color Color is the most difficult, because it is a 3-dimensional quantity. We are pretty good at color gradients, but discrete colors must be selected carefully. We need to be particularly aware of red/green color blindness issues. Visual perception and effective visualizations Here are some facts to keep in mind about visual perception from Now You See It: Visual perception is selective, and our attention is often drawn to constrasts from the norm. Figure 3.19: Our attention is drawn to contrasts to the norm. What stands out in this example image?, which is originally from C. Ware, Information Visualization: Perception for Design, 2004? Source: S. Few, Now You See It, 2009, p. 33. Implication: We should design visualizations so that the features we want to highlight stand out in contrast from those that are not worth the audience’s attention. Our eyes are drawn to familiar patterns. We see what we know and expect. Figure 3.20: Do you see anything embedded in this rose image from coolbubble.com? Source: S. Few, Now You See It, 2009, p. 34. Implication: Visualizations work best when they display information as patterns that familiar and easy to spot. Memory plays an important role in human cognition, but working memory is extremely limited. Implication: Visualizations must serve as external aids to augment working memory. If a visualization is unfamiliar, then it won’t be as effective. Gestalt principles The Gestalt principles (more info here or here) were developed by psychologists including Max Wertheimer in the early 1900s to explain how humans perceive organized patterns and objects. In a design setting, they help us understand how to incorporate preattentive features into visualizations. The figure below shows some preattentive features, all of which are processed prior to conscious attention (“at a glance”) and can help the reader focus on relevant information in a visualization. Figure 3.21: Preattentive features based on the Gestalt principles. Source: I. Meirelles, Design for Information, 2013, p. 23. Other design tips from Visualize This and Storytelling with Data: Put yourself in a reader’s shoes when you design data graphics. What parts of the data need explanation? We can minimize ambiguity by providing guides, label axes, etc. Data graphics are meant to shine a light on your data. Try to remove any elements that don’t help you do that. That is, eliminate “chart junk” (distracting and unnecessary adornments). Vary color and stroke styles to emphasize the parts in your graphic that are most important to the story you’re telling It is easier to judge length than it is to judge area or angles Be thoughtful about how your categories (levels) are ordered for categorical data. There may be a natural ordering Pie charts, donut charts, and 3D are evil Basic Rules for Constructing Graphics Instead of memorizing which plot is appropriate for which situation, it’s best to simply start to recognize patterns in constructing graphics: Each quantitative variable requires a new axis. Each categorical variable requires a new way to “group” the graphic (eg: using colors, shapes, separate facets, etc to capture the grouping). For visualizations in which overlap in glyphs or plots obscures the patterns, try faceting or transparency. Still to Come While we will not cover all of visualization theory – you can take a whole course on that at Macalester and it is a proper field in its own right – we will touch on the following types of visualizations in the coming weeks: Univariate and bivariate visualizations Visualizations of higher dimensional data Temporal structures: timelines and flows Hierarchical structures: trees Relational structures: networks Spatial structures: maps Spatio-temporal structures Textual structures Interactive graphics (e.g., gganimate, shiny) Exercises Exercise 3.2 Consider one of the more complicated data graphics listed at (http://mdsr-book.github.io/exercises.html#exercise_25): What story does the data graphic tell? What is the main message that you take away from it? Can the data graphic be described in terms of the Grammar of Graphics (frame, glyphs, aesthetics, facet, scale, guide)? If so, please describe. Critique and/or praise the visualization choices made by the designer. Do they work? Are they misleading? Thought-provoking? Brilliant? Are there things that you would have done differently? Justify your response. A “negative” result (e.g., there is no correlation between two variables) is a perfectly fine story to tell.↩︎ This list is from B. S. Baumer, D. T. Kaplan, and N. J. Horton, Modern Data Science with R, 2017, p. 15. For more of the theory of perception, see also W.S. Cleveland and R. McGill, “Graphical perception: Theory, experimentation, and application to the development of graphical methods,” Journal of the American Statistical Association, 1984.↩︎ "],["bivariate-visualizations.html", "Topic 4 Bivariate Visualizations Learning Goals Bivariate Visualizations Appendix: R Functions", " Topic 4 Bivariate Visualizations Learning Goals Identify appropriate types of bivariate visualizations, depending on the type of variables (categorical, quantitative) Create basic bivariate visualizations based on real data You can download a template .Rmd of this activity here. Put the file in a Day_04 folder within your COMP_STAT_112 folder. Bivariate Visualizations The outcome of the 2016 presidential election surprised many people. In this activity we will analyze data from the 2016 presidential election. To better understand it ourselves, we’ll explore county-level election outcomes and demographics. The data set, prepared by Alicia Johnson, combines 2008/2012/2016 county-level election returns from Tony McGovern on github, county-level demographics from the df_county_demographics data set within the choroplethr R package, and red/purple/blue state designations from http://www.270towin.com/. Getting to know the dataset Exercise 4.1 Begin by loading the data from “https://www.macalester.edu/~ajohns24/data/electionDemographics16.csv” and getting to know the data. Follow the prompts below to guide you. # Load data from &quot;https://www.macalester.edu/~ajohns24/data/electionDemographics16.csv&quot; elect &lt;- read_csv(&quot;https://www.macalester.edu/~ajohns24/data/electionDemographics16.csv&quot;) # Check out the first rows of elect. What are the units of observation? # How much data do we have? # What are the names of the variables? Solution # Load data from &quot;https://www.macalester.edu/~ajohns24/data/electionDemographics16.csv&quot; elect &lt;- read_csv(&quot;https://www.macalester.edu/~ajohns24/data/electionDemographics16.csv&quot;) # Check out the first rows of elect. # The units of observation are county election results # The variables are county name, vote counts for parties and total for presidential elections, and more head(elect) ## # A tibble: 6 × 34 ## county total…¹ dem_2…² gop_2…³ oth_2…⁴ total…⁵ dem_2…⁶ gop_2…⁷ oth_2…⁸ total…⁹ dem_2…˟ gop_2…˟ oth_2…˟ ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Walker … 28652 7420 20722 510 28497 6551 21633 313 29243 4486 24208 549 ## 2 Bullock… 5415 4011 1391 13 5318 4058 1250 10 4701 3530 1139 32 ## 3 Calhoun… 49242 16334 32348 560 46240 15500 30272 468 47376 13197 32803 1376 ## 4 Barbour… 11630 5697 5866 67 11459 5873 5539 47 10390 4848 5431 111 ## 5 Fayette… 7957 1994 5883 80 7912 1803 6034 75 8196 1358 6705 133 ## 6 Baldwin… 81413 19386 61271 756 84988 18329 65772 887 94090 18409 72780 2901 ## # … with 21 more variables: perdem_2016 &lt;dbl&gt;, perrep_2016 &lt;dbl&gt;, winrep_2016 &lt;lgl&gt;, perdem_2012 &lt;dbl&gt;, ## # perrep_2012 &lt;dbl&gt;, winrep_2012 &lt;lgl&gt;, perdem_2008 &lt;dbl&gt;, perrep_2008 &lt;dbl&gt;, winrep_2008 &lt;lgl&gt;, ## # region &lt;dbl&gt;, total_population &lt;dbl&gt;, percent_white &lt;dbl&gt;, percent_black &lt;dbl&gt;, percent_asian &lt;dbl&gt;, ## # percent_hispanic &lt;dbl&gt;, per_capita_income &lt;dbl&gt;, median_rent &lt;dbl&gt;, median_age &lt;dbl&gt;, polyname &lt;chr&gt;, ## # abb &lt;chr&gt;, StateColor &lt;chr&gt;, and abbreviated variable names ¹​total_2008, ²​dem_2008, ³​gop_2008, ## # ⁴​oth_2008, ⁵​total_2012, ⁶​dem_2012, ⁷​gop_2012, ⁸​oth_2012, ⁹​total_2016, ˟​dem_2016, ˟​gop_2016, ˟​oth_2016 # There are 3,112 counties and 34 variables dim(elect) ## [1] 3112 34 # See the long list below names(elect) ## [1] &quot;county&quot; &quot;total_2008&quot; &quot;dem_2008&quot; &quot;gop_2008&quot; &quot;oth_2008&quot; ## [6] &quot;total_2012&quot; &quot;dem_2012&quot; &quot;gop_2012&quot; &quot;oth_2012&quot; &quot;total_2016&quot; ## [11] &quot;dem_2016&quot; &quot;gop_2016&quot; &quot;oth_2016&quot; &quot;perdem_2016&quot; &quot;perrep_2016&quot; ## [16] &quot;winrep_2016&quot; &quot;perdem_2012&quot; &quot;perrep_2012&quot; &quot;winrep_2012&quot; &quot;perdem_2008&quot; ## [21] &quot;perrep_2008&quot; &quot;winrep_2008&quot; &quot;region&quot; &quot;total_population&quot; &quot;percent_white&quot; ## [26] &quot;percent_black&quot; &quot;percent_asian&quot; &quot;percent_hispanic&quot; &quot;per_capita_income&quot; &quot;median_rent&quot; ## [31] &quot;median_age&quot; &quot;polyname&quot; &quot;abb&quot; &quot;StateColor&quot; Exercise 4.2 Explore the win column: The winrep_2016 variable indicates whether or not the Republican (Trump) won the county in 2016, thus is categorical. Let’s construct both numerical and visual summaries of Trump wins/losses. (Before you do, what do you anticipate?) # Construct a table (a numerical summary) of the number of counties that Trump won/lost table(xxx) # fill in the xxx # Attach a library needed for ggplots library(xxx) # Construct a bar chart (a visual summary) of this variable. ggplot(xxx, aes(xxx)) + geom_xxx() Solution # Construct a table (a numerical summary) of the number of counties that Trump won/lost table(elect$winrep_2016) ## ## FALSE TRUE ## 487 2625 # Attach a library needed for ggplots library(ggplot2) # Construct a bar chart (a visual summary) of this variable. ggplot(elect, aes(x = winrep_2016)) + geom_bar() Exercise 4.3 (Explore Vote Percentages) The perrep_2016 variable includes a bit more detail about Trump’s support in each county. Since it’s quantitative we need different tools to visually explore the variability in perrep_2016. To this end, construct &amp; interpret both a histogram and density plot of perrep_2016. (Before you do, what do you anticipate?) # histogram ggplot(elect, aes(xxx)) + geom_xxx(color = &quot;white&quot;) # density plot ggplot(elect, aes(xxx)) + geom_xxx() Solution # histogram ggplot(elect, aes(x = perrep_2016)) + geom_histogram(color = &quot;white&quot;) # density plot ggplot(elect, aes(x = perrep_2016)) + geom_density() The vast majority of counties in the U.S. had a Republican majority vote (&gt; 50%) within that county. Thus far, we have a good sense for how Trump’s support varied from county to county. We don’t yet have a good sense for why. What other variables (ie. county features) might explain some of the variability in Trump’s support from county to county? Which of these variables do you think will be the best predictors of support? The worst? Solution Maybe past election history and information about the people that live there and the social culture and values. Let’s see… Background on visualizing relationships We’ve come up with a list of variables that might explain some of the variability in Trump’s support from county to county. Thus we’re interested in the relationship between: response variable: the variable whose variability we would like to explain (Trump’s percent of the vote) predictors: variables that might explain some of the variability in the response (percent white, per capita income, state color, etc) Our goal is to construct visualizations that allow us to examine/identify the following features of the relationships among these variables: relationship trends (direction and form) relationship strength (degree of variability from the trend) outliers in the relationship Before constructing visualizations of the relationship among any set of these variables, we need to understand what features these should have. As with univariate plots, the appropriate visualization also depends upon whether the variables are quantitative or categorical. Recall some basic rules in constructing graphics: Each quantitative variable requires a new axis. (We’ll discuss later what to do when we run out of axes!) Each categorical variable requires a new way to “group” the graphic (eg: using colors, shapes, separate facets, etc to capture the grouping) For visualizations in which overlap in glyphs or plots obscures the patterns, try faceting or transparency. Exercise 4.4 (Mock-Ups) Consider a subset of the variables: county abb perrep_2016 perrep_2012 winrep_2016 StateColor Elbert County CO 73.53 72.52 TRUE blue Rockdale County GA 35.82 41.37 FALSE purple Clay County MN 46.55 44.91 TRUE blue McDonald County MO 80.15 72.84 TRUE purple Alcorn County MS 79.95 75.11 TRUE red Roger Mills County OK 87.94 83.75 TRUE red In groups, sketch on paper a mock-up of a visualization of the relationship between the given pair of variables (i.e., what type of chart is appropriate to demonstrate the relationship?): The relationship between perrep_2016 (the response) and perrep_2012 (the predictor). The relationship between perrep_2016 (the response) and StateColor (the predictor). Think: how might we modify the below density plot of perrep_2016 to distinguish between counties in red/purple/blue states? ggplot(elect, aes(x = perrep_2016)) + geom_density() The relationship between Trump’s county-levels wins/losses winrep_2016 (the response) and StateColor (the predictor). Think: how might we modify the below bar plot of winrep_2016 to distinguish between counties in red/purple/blue states? ggplot(elect, aes(x = winrep_2016)) + geom_bar() Visualizing quantitiative vs quantitative relationships Let’s start by exploring the relationship between Trump’s 2016 support (perrep_2016) and Romney’s 2012 support (perrep_2012), both quantitative variables. Exercise 4.5 (Scatterplots and Glyphs) Both perrep_2016 and perrep_2012 are quantitative, thus require their own axes. Traditionally, the response variable (what we are trying to predict or explain) is placed on the y-axis. Once the axes are set up, each case is represented by a “glyph” at the coordinates defined by these axes. Make a scatterplot of perrep_2016 vs perrep_2012 with different glyphs: points or text. # just a graphics frame ggplot(elect, aes(y = perrep_2016, x = perrep_2012)) # add a layer with &quot;point&quot; glyphs ggplot(elect, aes(y = perrep_2016, x = perrep_2012)) + geom_point() # add a layer with symbol glyphs ggplot(elect, aes(y = perrep_2016, x = perrep_2012)) + geom_point(shape = 3) # add a layer with &quot;text&quot; glyphs ggplot(elect, aes(y = perrep_2016, x = perrep_2012)) + geom_text(aes(label = abb)) Solution # just a graphics frame ggplot(elect, aes(y = perrep_2016, x = perrep_2012)) # add a layer with &quot;point&quot; glyphs ggplot(elect, aes(y = perrep_2016, x = perrep_2012)) + geom_point() # add a layer with symbol glyphs ggplot(elect, aes(y = perrep_2016, x = perrep_2012)) + geom_point(shape = 3) # add a layer with &quot;text&quot; glyphs ggplot(elect, aes(y = perrep_2016, x = perrep_2012)) + geom_text(aes(label = abb)) ## Warning: Removed 398 rows containing missing values (geom_text). Summarize the relationship between the Republican candidates’ support in 2016 and 2012. Be sure to comment on: - the strength of the relationship (weak/moderate/strong) - the direction of the relationship (positive/negative) - outliers (In what state do counties deviate from the national trend? Explain why this might be the case) Solution There is a strong positive relationship between the Republican support from 2012 to 2016, meaning that if a county highly favors a Republican candidate in 2012, they were likely to highly favor a Republican in 2016. Counties in Utah seems to not quite follow this pattern with lower support in 2016 than what you’d expect given the support in 2012. This is because the 2012 candidate was from Utah (data context!). Exercise 4.6 (Capture the Trend with 'smooths') The trend of the relationship between perrep_2016 and perrep_2012 is clearly positive and (mostly) linear. We can highlight this trend by adding a model “smooth” to the plot. Add a layer with a model smooth: ggplot(elect, aes(y = perrep_2016, x = perrep_2012)) + geom_point() + geom_smooth() Solution ggplot(elect, aes(y = perrep_2016, x = perrep_2012)) + geom_point() + geom_smooth()   Construct a new plot that contains the model smooth but does not include the individual cases (eg: point glyphs). Solution ggplot(elect, aes(y = perrep_2016, x = perrep_2012)) + geom_smooth() Notice that there are gray bands surrounding the blue model smooth line. What do these gray bars illustrate/capture and why are they widest at the “ends” of the model? Solution There are fewer data points at the “ends” so there is more uncertainty about the relationship. By default, geom_smooth adds a smooth, localized model line. To examine the “best” linear model, we can specify method=\"lm\": ggplot(elect, aes(y = perrep_2016, x = perrep_2012)) + geom_point() + geom_smooth(method = &quot;lm&quot;) Solution ggplot(elect, aes(y = perrep_2016, x = perrep_2012)) + geom_point() + geom_smooth(method = &quot;lm&quot;) Exercise 4.7 (Modify the Scatterplots) As with univariate plots, we can change the aesthetics of scatterplots. Add appropriate axis labels to your scatterplot. Label the y-axis “Trump 2016 support (%)” and label the x-axis “Romney 2012 support (%)”. Change the color of the points. Add some transparency to the points. NOTE: alpha can be between 0 (complete transparency) and 1 (no transparency). Why is transparency useful in this particular graphic? Solution ggplot(elect, aes(y = perrep_2016, x = perrep_2012)) + geom_point(color = &quot;red&quot;, alpha = 0.1) + labs(x = &quot;Romney 2012 support (%)&quot;, y = &quot;Trump 2016 support (%)&quot;) + theme_classic() Exercise 4.8 (More Scatterplots) 2012 results aren’t the only possible predictor of 2016 results. Consider two more possibilities. Construct a scatterplot of perrep_2016 and median_rent. Summarize the relationship between these two variables. Construct a scatterplot of perrep_2016 and percent_white. Summarize the relationship between these two variables. Among perrep_2012, median_rent and percent_white, which is the best predictor of perrep_2016? Why? Visualizing quantitative vs. categorical relationships Consider a univariate histogram and density plot of perrep_2016: To visualize the relationship between Trump’s 2016 support (perrep_2016) and the StateColor (categorical) we need to incorporate a grouping mechanism. Work through the several options below. Exercise 4.9 (Side-by-Side Density Plots) We can show density plots for each state color next to each other: Construct a density plot for each group. ggplot(elect, aes(x = perrep_2016, fill = StateColor)) + geom_density() Notice that ggplot randomly assigns colors to group based on alphabetical order. In this example, the random color doesn’t match the group itself (red/purple/blue)! We can fix this: ggplot(elect, aes(x = perrep_2016, fill = StateColor)) + geom_density() + scale_fill_manual(values = c(&quot;blue&quot;, &quot;purple&quot;, &quot;red&quot;)) The overlap between the groups makes it difficult to explore the features of each. One option is to add transparency to the density plots: ggplot(elect, aes(x = perrep_2016, fill = StateColor)) + geom_density(alpha = 0.5) + scale_fill_manual(values = c(&quot;blue&quot;, &quot;purple&quot;, &quot;red&quot;)) Yet another option is to separate the density plots into separate “facets” defined by group: ggplot(elect, aes(x = perrep_2016, fill = StateColor)) + geom_density(alpha = 0.5) + scale_fill_manual(values = c(&quot;blue&quot;, &quot;purple&quot;, &quot;red&quot;)) + facet_wrap(~ StateColor) Exercise 4.10 (Side-by-Side Histograms) Let’s try a similar strategy using histograms to illustrate the relationship between perrep_2016 and StateColor. Start with the default histogram: ggplot(elect, aes(x = perrep_2016, fill = StateColor)) + geom_histogram(color = &quot;white&quot;) That’s not very helpful! Separate the histograms into separate facets for each StateColor group. Exercise 4.11 (More Options!) Density plots and histograms aren’t the only type of viz we might use… Construct side-by-side violins and side-by-side boxplots (see description below). # violins instead ggplot(elect, aes(y = perrep_2016, x = StateColor)) + geom_violin() # boxes instead ggplot(elect, aes(y = perrep_2016, x = StateColor)) + geom_boxplot() Box plots are constructed from five numbers - the minimum, 25th percentile, median, 75th percentile, and maximum value of a quantitative variable: In the future, we’ll typically use density plots instead of histograms, violins, and boxes. Explain at least one pro and one con of the density plot. Exercise 4.12 Let’s not forget the most important purpose of these visualizations! Summarize the relationship between Trump’s 2016 county-level support among red/purple/blue states. Visualizing categorical vs categorical relationships Finally, suppose that instead of Trump’s percentage support, we simply want to explore his county-level wins/losses: Specifically, let’s explore the relationship between winrep_2016 and StateColor, another categorical variable. Exercise 4.13 (Side-by-side bar plots) We saw above that we can incorporate a new categorical variable into a visualization by using grouping features such as color or facets. Let’s add information about StateColor to our bar plot of winrep_2016. Construct the following 4 bar plot visualizations. # a stacked bar plot ggplot(elect, aes(x = StateColor, fill = winrep_2016)) + geom_bar() # a side-by-side bar plot ggplot(elect, aes(x = StateColor, fill = winrep_2016)) + geom_bar(position = &quot;dodge&quot;) # a proportional bar plot ggplot(elect, aes(x = StateColor, fill = winrep_2016)) + geom_bar(position = &quot;fill&quot;) # faceted bar plot ggplot(elect, aes(x = StateColor, fill = winrep_2016)) + geom_bar() + facet_wrap(~winrep_2016) Name one pro and one con of using the “proportional bar plot” instead of one of the other three options. What’s your favorite bar plot from part (a)? Why? Practice Hot Dogs In the annual Nathan’s hot dog eating contest, people compete to eat as many hot dogs as possible in ten minutes. Data on past competitions were compiled by Nathan Yau for “Visualize This: The FlowingData Guide to Design, Visualization, and Statistics”: hotdogs &lt;- read_csv(&quot;http://datasets.flowingdata.com/hot-dog-contest-winners.csv&quot;) Exercise 4.14 Address the following: Construct a visualization of the winning number of hot dogs by year. THINK: Which is the response variable? Temporal trends are often visualized using a line plot. Add a geom_line() layer to your plot from part (a). Summarize your observations about the temporal trends in the hot dog contest. Exercise 4.15 All but two of the past winners are from the U.S. or Japan: table(hotdogs$Country) ## ## Germany Japan Mexico United States ## 1 9 1 20 Use the following code to filter out just the winners from U.S. and Japan and name this hotdogsSub. (Don’t worry about the code itself - we’ll discuss similar syntax later in the semester!) library(dplyr) hotdogsSub &lt;- hotdogs %&gt;% filter(Country %in% c(&quot;Japan&quot;, &quot;United States&quot;)) Using a density plot approach without facets, construct a visualization of how the number of hot dogs eaten varies by country. Repeat part a using a density plot approach with facets. Repeat part a using something other than a density plot approach. (There are a few options!) Summarize your observations about the number of hot dogs eaten by country. The Bechdel Test Recall the “Bechdel test” data from the previous activity. As a reminder, the “Bechdel test” tests whether movies meet the following criteria: there are \\(\\ge\\) 2 female characters the female characters talk to each other at least 1 time, they talk about something other than a male character In the fivethirtyeight.com article “The Dollar-And-Cents Case Against Hollywood’s Exclusion of Women”, the authors analyze which Hollywood movies do/don’t pass the test. Their data are available in the fivethirtyeight package: library(fivethirtyeight) data(bechdel) In investigating budgets and profits, the authors “focus on films released from 1990 to 2013, since the data has significantly more depth since then.” Use the following code to filter out just the movies in these years and name the resulting data set Beyond1990 (don’t worry about the syntax): library(dplyr) Beyond1990 &lt;- bechdel %&gt;% filter(year &gt;= 1990) Exercise 4.16 Address the following: Construct a visualization that addresses the following research question: Do bigger budgets (budget_2013) pay off with greater box office returns (domgross_2013)? In constructing this visualization, add a smooth to highlight trends and pay attention to which of these variables is the response. Using your visualization as supporting evidence, answer the research question. Part of the fivethirtyeight article focuses on how budgets (budget_2013) differ among movies with different degrees of female character development (clean_test). Construct a visualization that highlights the relationship between these two variables. There are many options - some are better than others! Using your visualization as supporting evidence, address fivethirtyeight’s concerns. Exercise 4.17 NOTE: The following exercise is inspired by a similar exercise proposed by Albert Kim, one of the fivethirtyeight package authors. Return to the fivethirtyeight.com article and examine the plot titled “The Bechdel Test Over Time”. Summarize the trends captured by this plot. (How has the representation of women in movies evolved over time?) Recreate this plot from the article! To do so, you’ll need to create a new data set named newbechdel in which the order of the Bechdel categories (clean_test) and the year categories (yearCat) match those used by fivethirtyeight. Don’t worry about the syntax: library(dplyr) newbechdel &lt;- bechdel %&gt;% mutate(clean_test = factor(bechdel$clean_test, c(&quot;nowomen&quot;, &quot;notalk&quot;, &quot;men&quot;, &quot;dubious&quot;, &quot;ok&quot;))) %&gt;% mutate(yearCat = cut(year, breaks = seq(1969, 2014, by = 5))) Further, you’ll need to add the following layer in order to get a color scheme that’s close to that in the article: scale_fill_manual(values = c(&quot;red&quot;, &quot;salmon&quot;, &quot;pink&quot;, &quot;steelblue1&quot;, &quot;steelblue4&quot;)) NOTE: that your plot won’t look exactly like the authors’, but should be close to this: Appendix: R Functions Data Wrangling R functions Function/Operator Action Example filter(data,condition) Provide rows of a data set that satisfy a condition bechdel %&gt;% filter(year &gt;= 1990) mutate(data,varname =) Create a new variable bechdel %&gt;% mutate(yearCat = cut(year, breaks = seq(1969, 2014, by = 5))) cut(x,breaks) Cut a quantitative variable into categories by the break points bechdel %&gt;% mutate(yearCat = cut(year, breaks = seq(1969, 2014, by = 5))) ggplot2 foundation functions Function/Operator Action Example ggplot(data) Create a blank canvas that can create a visualization based on data ggplot(data = elect) + geom_bar(aes(x)) Add a bar plot geom_bar(aes(x = winrep_2016)) + geom_bar(aes(x,fill),position='fill') Add a propotional bar plot geom_bar(aes(x = winrep_2016,fill = StateColor),position='fill') + geom_bar(aes(x,fill),position='dodge') Add a side-by-side bar plot geom_bar(aes(x = winrep_2016,fill = StateColor),position='dodge') + geom_smooth(aes(x,y)) Add a smoothed average curve of scatterplot geom_smooth() + geom_smooth(aes(x,y),method='lm') Add a best fit line to a scatterplot geom_smooth(method='lm') + geom_point(aes(x,y)) Add a scatterplot geom_bar(aes(x = year,y=budget_2013)) + geom_text(aes(x,y,label)) Add a text to a plot geom_text(aes(label=abb)) + facet_wrap(~x) Facet a plot (break into subplots based on groups) facet_wrap(~StateColor) "],["multivariate-visualizations.html", "Topic 5 Multivariate Visualizations Learning Goals Adding More Aesthetic Attributes Other Multivariate Visualization Techniques", " Topic 5 Multivariate Visualizations Learning Goals Understand how we can use additional aesthetics such as color and size to incorporate a third (or more variables) to a bivariate plot Develop comfort with interpreting heat maps and star plots, which allow you to look for patterns in variation in many variables. You can download a template .Rmd of this activity here. Put this in a new folder called Day_05 in your folder for COMP_STAT_112. Adding More Aesthetic Attributes Exploring SAT Scores Though far from a perfect assessment of academic preparedness, SAT scores have historically been used as one measurement of a state’s education system. The education data stored at https://www.macalester.edu/~ajohns24/data/sat.csv contain various education variables for each state: education &lt;- read.csv(&quot;https://www.macalester.edu/~ajohns24/data/sat.csv&quot;) Table 5.1: The first few rows of the SAT data. State expend ratio salary frac verbal math sat fracCat Alabama 4.405 17.2 31.144 8 491 538 1029 (0,15] Alaska 8.963 17.6 47.951 47 445 489 934 (45,100] Arizona 4.778 19.3 32.175 27 448 496 944 (15,45] Arkansas 4.459 17.1 28.934 6 482 523 1005 (0,15] California 4.992 24.0 41.078 45 417 485 902 (15,45] Colorado 5.443 18.4 34.571 29 462 518 980 (15,45] A codebook is provided by Danny Kaplan who also made these data accessible: Figure 5.1: Codebook for SAT data. Source: https://www.macalester.edu/~kaplan/ISM/datasets/data-documentation.pdf To examine the variability in average SAT scores from state to state, let’s start with a univariate density plot: ggplot(education, aes(x = sat)) + geom_density(fill = &quot;blue&quot;, alpha = .5) The first question we’d like to answer is to what degree do per pupil spending (expend) and teacher salary explain this variability? We can start by plotting each against sat, along with a best fit linear regression model: ggplot(education, aes(y = sat, x = salary)) + geom_point() + geom_smooth(se = FALSE, method = &quot;lm&quot;) + theme_classic() ggplot(education, aes(y = sat, x = expend)) + geom_point() + geom_smooth(se = FALSE, method = &quot;lm&quot;) + theme_classic() Exercise 5.1 Is there anything that surprises you in the above plots? What are the relationship trends? Solution These seem to suggest that spending more money on students or teacher salaries correlates with lower SAT scores. Say it ain’t so! Exercise 5.2 Make a single scatterplot visualization that demonstrates the relationship between sat, salary, and expend. Summarize the trivariate relationship between sat, salary, and expend. Hints: 1. Try using the color or size aesthetics to incorporate the expenditure data. 2. Include some model smooths with geom_smooth() to help highlight the trends. Solution Below are four different plots. There seems to be a high correlation between expend and salary, and both seem to be negatively correlated with sat. #plot 1 g1 &lt;- ggplot(education, aes(y=sat, x=salary, color=expend)) + geom_point() + geom_smooth(se=FALSE, method=&quot;lm&quot;) + theme_classic() #plot 2 g2 &lt;- ggplot(education, aes(y=sat, x=salary, size=expend)) + geom_point() + geom_smooth(se=FALSE, method=&quot;lm&quot;) + theme_classic() #plot 3 g3 &lt;- ggplot(education, aes(y=sat, x=salary, color=cut(expend,2))) + geom_point() + geom_smooth(se=FALSE, method=&quot;lm&quot;) + theme_classic() #plot 4 g4 &lt;- ggplot(education, aes(y=sat, x=salary, color=cut(expend,3))) + geom_point() + geom_smooth(se=FALSE, method=&quot;lm&quot;) + theme_classic() library(gridExtra) grid.arrange(g1, g2, g3, g4, ncol=2) Exercise 5.3 The fracCat variable in the education data categorizes the fraction of the state’s students that take the SAT into low (below 15%), medium (15-45%), and high (at least 45%). Make a univariate visualization of the fracCat variable to better understand how many states fall into each category. Make a bivariate visualization that demonstrates the relationship between fracCat and sat. What story does your graphic tell? Make a trivariate visualization that demonstrates the relationship between fracCat, sat, and expend. Incorporate fracCat as the color of each point, and use a single call to geom_smooth to add three trendlines (one for each fracCat). What story does your graphic tell? Putting all of this together, explain this example of Simpson’s Paradox. That is, why does it appear that SAT scores decrease as spending increases even though the opposite is true? Other Multivariate Visualization Techniques Heat maps Note that each variable (column) is scaled to indicate states (rows) with high values (yellow) to low values (purple/blue). With this in mind you can scan across rows &amp; across columns to visually assess which states &amp; variables are related, respectively. You can also play with the color scheme. Type ?cm.colors in the console to see various options. ed &lt;- as.data.frame(education) # convert from tibble to data frame # convert to a matrix with State names as the row names row.names(ed) &lt;- ed$State ed &lt;- ed[, 2:8] ed_mat &lt;- data.matrix(ed) heatmap.2(ed_mat, Rowv = NA, Colv = NA, scale = &quot;column&quot;, keysize = 0.7, density.info = &quot;none&quot;, col = hcl.colors(256), margins = c(10, 20), colsep = c(1:7), rowsep = (1:50), sepwidth = c(0.05, 0.05), sepcolor = &quot;white&quot;, cexRow = 2, cexCol = 2, trace = &quot;none&quot;, dendrogram = &quot;none&quot; ) Exercise 5.4 What do you notice? What insight do you gain about the variation across U.S. states? Heat map with row clusters It can be tough to identify interesting patterns by visually comparing across rows and columns. Including dendrograms helps to identify interesting clusters. heatmap.2(ed_mat, Colv = NA, scale = &quot;column&quot;, keysize = .7, density.info = &quot;none&quot;, col = hcl.colors(256), margins = c(10, 20), colsep = c(1:7), rowsep = (1:50), sepwidth = c(0.05, 0.05), sepcolor = &quot;white&quot;, cexRow = 2, cexCol = 2, trace = &quot;none&quot;, dendrogram = &quot;row&quot; ) Exercise 5.5 What do you notice? What new insight do you gain about the variation across U.S. states, now that states are grouped and ordered to represent similarity? Heat map with column clusters We can also construct a heat map which identifies interesting clusters of columns (variables). heatmap.2(ed_mat, Rowv = NA, scale = &quot;column&quot;, keysize = .7, density.info = &quot;none&quot;, col = hcl.colors(256), margins = c(10, 20), colsep = c(1:7), rowsep = (1:50), sepwidth = c(0.05, 0.05), sepcolor = &quot;white&quot;, cexRow = 2, cexCol = 2, trace = &quot;none&quot;, dendrogram = &quot;column&quot; ) Exercise 5.6 What do you notice? What new insight do you gain about the variation across U.S. states, now that variables are grouped and ordered to represent similarity? Star plots There’s more than one way to visualize multivariate patterns. Like heat maps, these star plot visualizations indicate the relative scale of each variable for each state. With this in mind, you can use the star maps to identify which state is the most “unusual.” You can also do a quick scan of the second image to try to cluster states. How does that clustering compare to the one generated in the heat map with row clusters above? stars(ed_mat, flip.labels = FALSE, key.loc = c(15, 1.5), cex = 1.5 ) stars(ed_mat, flip.labels = FALSE, key.loc = c(15, 1.5), cex = 1.5, draw.segments = TRUE ) Exercise 5.7 What do you notice? What new insight do you gain about the variation across U.S. states with the star plots? "],["spatial-visualization.html", "Topic 6 Spatial Visualization Learning Goals Motivation Plotting Points on a Map Contour Maps Choropleths Dynamnic Maps with leaflet", " Topic 6 Spatial Visualization Learning Goals Plot data points on top of a map using the ggmap() function along with ggplot2 functions Create choropleth maps using geom_map() Add points and other ggplot2 features to a map created from geom_map() Understand the basics of creating a map using leaflet, including adding points and choropleths to a base map You can download a template .Rmd of this activity here. Put this in a new folder called Day_06 in your folder for COMP_STAT_112. Motivation Take a look at these to get motivated/inspired to make your own: NYT article on effects of redlining NY Times mayoral primaries Super zip shiny app Plotting Points on a Map There are many ways we could visually represent data on a map. The first we’ll talk about it in terms of points in a coordinate system (longitudinal, latitude). Starbucks Example The Starbucks data, compiled by Danny Kaplan, contains information about every Starbucks in the world at the time the data were collected. It includes the Latitude and Longitude of each location. Let’s start by using familiar ggplot plotting tools. # Starbucks locations Starbucks &lt;- read_csv(&quot;https://www.macalester.edu/~ajohns24/data/starbucks.csv&quot;) ggplot(data = Starbucks) + geom_point(aes(x = Longitude, y = Latitude), alpha = 0.2, size = 0.2 ) + theme_classic() The code for a point pattern probably looks familiar. To highlight the geographical nature of this scatterplot, we can superimpose the points on top of a background map, using the ggmap() function from the ggmap library. NOTE: We used to be able to easily bring in Google maps. As of mid-2018, in order to bring those in, you need to have a registered API key with Google. If you want to do that, see google_key in the help. Then, see the documentation for get_map(). We will bring in other types of maps since Google maps are harder to do now and require you to submit credit card information. We will use a stamen map as our background. You can also take a look at stamen maps on their website. First, let’s look at an example. # Get the map information world &lt;- get_stamenmap( bbox = c(left = -180, bottom = -57, right = 179, top = 82.1), maptype = &quot;terrain&quot;, zoom = 2 ) # Plot the points on the map ggmap(world) + # creates the map &quot;background&quot; geom_point( data = Starbucks, aes(x = Longitude, y = Latitude), alpha = .3, size = 0.2 ) + theme_map() Next, we will walk through the get_stamenmap() function inputs or arguments. The code below is what was used to get the world map information. get_stamenmap( bbox = c(left = -180, bottom = -57, right = 179, top = 82.1), maptype = &quot;terrain&quot;, zoom = 2 ) bbox get_stamenmap(&nbsp;&nbsp;bbox = c(left = -180, bottom = -57, right = 179, top = 82.1),&nbsp;&nbsp;maptype = \"terrain\",&nbsp;&nbsp;zoom = 2) The bbox argument tells it the minimum and maximum latitude and longitude points. So, left is the minimum longitude, right is the maximum longitude, bottom is the minimum latitude, and top is the maximum latitude. One helpful trick is to go to openstreetmap: zoom in on the area of interest, click export, and you will see all the values you need. You may have to modify them slightly, which you can do after your initial plot. maptype get_stamenmap(&nbsp;&nbsp;bbox = c(left = -180, bottom = -57, right = 179, top = 82.1),&nbsp;&nbsp;maptype = \"terrain\",&nbsp;&nbsp;zoom = 2) The maptype tells it the style of the map. Check out the different options by looking in the get_stamenmap help (type ?get_stamenmap in the console). zoom get_stamenmap(&nbsp;&nbsp;bbox = c(left = -180, bottom = -57, right = 179, top = 82.1),&nbsp;&nbsp;maptype = \"terrain\",&nbsp;&nbsp;zoom = 2) When you make a large area, you need to decrease the zoom, otherwise it will take too long to load. So, it’s a good idea to start with a small zoom and you can always make it bigger if you want. This might seem counter-intuitive at first. Think of the zoom level as the level of detail. So, smaller numbers show less detail and larger numbers more detail. A good trick is to go to the stamanmaps webpage and search for the location you are mapping. Then, in the URL, you can see the zoom number. For example, this link is a map of St. Paul: http://maps.stamen.com/#terrain/12/44.9531/-93.0904. Notice the number 12 next to /#terrain/. That means it is zoomed in at 12. ggmap() We save the the map information from get_stamenmap() to a named value and then use it in ggmap(): # Get the map informationworld get_stamenmap(&nbsp;&nbsp;bbox = c(left = -180, bottom = -57, right = 179, top = 82.1),&nbsp;&nbsp;maptype = \"terrain\",&nbsp;&nbsp;zoom = 2)# Plot the points on the mapggmap(world) + # creates the map \"background\"&nbsp;&nbsp;geom_point(&nbsp;&nbsp;&nbsp;&nbsp;data = Starbucks,&nbsp;&nbsp;&nbsp;&nbsp;aes(x = Longitude, y = Latitude),&nbsp;&nbsp;&nbsp;&nbsp;alpha = .3,&nbsp;&nbsp;&nbsp;&nbsp;size = 0.2&nbsp;&nbsp;) +&nbsp;&nbsp;theme_map() The ggmap() function will print the “background” map. Think of it as the providing the canvas on which we will plot. This takes the place of our usual ggplot(). ggmap(world) After that, we can use the geom_XXX() functions from ggplot2 that we are used to in order to put points, lines, etc. on top of the map. But, we need to remember to also provide the data we are using in the geom_XXX() function(s) we use since we do not have the ggplot() function in which to provide it. # Get the map informationworld &nbsp;&nbsp;bbox = c(left = -180, bottom = -57, right = 179, top = 82.1),&nbsp;&nbsp;maptype = \"terrain\",&nbsp;&nbsp;zoom = 2)# Plot the points on the mapggmap(world) + # creates the map \"background\"&nbsp;&nbsp;geom_point(&nbsp;&nbsp;&nbsp;&nbsp;data = Starbucks,&nbsp;&nbsp;&nbsp;&nbsp;aes(x = Longitude, y = Latitude),&nbsp;&nbsp;&nbsp;&nbsp;alpha = .3,&nbsp;&nbsp;&nbsp;&nbsp;size = 0.2&nbsp;&nbsp;) +&nbsp;&nbsp;theme_map() theme_map() The last line of the code is theme_map(). This is optional, but it often makes it look nice. # Get the map informationworld &nbsp;&nbsp;bbox = c(left = -180, bottom = -57, right = 179, top = 82.1),&nbsp;&nbsp;maptype = \"terrain\",&nbsp;&nbsp;zoom = 2)# Plot the points on the mapggmap(world) + # creates the map \"background\"&nbsp;&nbsp;geom_point(&nbsp;&nbsp;&nbsp;&nbsp;data = Starbucks,&nbsp;&nbsp;&nbsp;&nbsp;aes(x = Longitude, y = Latitude),&nbsp;&nbsp;&nbsp;&nbsp;alpha = .3,&nbsp;&nbsp;&nbsp;&nbsp;size = 0.2&nbsp;&nbsp;) +&nbsp;&nbsp;theme_map() So, the final map as a world map as the background with points plotted on top that show the Starbucks locations. The points are 20 percent (0.2) of their usual size and have a transparency level of 0.3. Resources Prof. Lendway’s demo video ggmap examples from ggmap maintainer David Kahle ggmap cheatsheet Exercise: More with Starbucks Exercise 6.1 Now it is your turn to work with the Starbucks data. Add an aesthetic to the world map that sets the color of the points according to the ownership type. What, if anything, can you deduce from this visualization? Construct a new map of Starbucks locations in the Twin Cities metro area (approximately the five county metro area). In the Twin Cities plot, play with the zoom number. What does it do? (just describe what it does - don’t actually include more than one map). Try a couple different map types (see get_stamenmap() in help and look at maptype). Include a map with one of the other map types. Add a point to the map that indicates Macalester College and label it appropriately. There are many ways you can do this, but it may be easiest with the annotate() function (see ggplot2 cheatsheet). Solution # a) ggmap(world) + geom_point( data = Starbucks, aes( x = Longitude, y = Latitude, color = `Ownership Type` ), alpha = .5, size = .2 ) + scale_color_manual(values = c(&quot;blue&quot;, &quot;red&quot;, &quot;black&quot;, &quot;purple&quot;)) + theme_map() + theme(legend.background = element_blank()) It appears that most of the locations in the western hemisphere are company owned or licensed, while franchising is more common in western Europe and joint ventures are more common in eastern Asia. # b) TwinCities &lt;- get_stamenmap( bbox = c(left = -94, bottom = 44.5, right = -92.5, top = 45.5), maptype = &quot;toner&quot;, zoom = 10 ) ggmap(TwinCities) + geom_point( data = Starbucks, aes(x = Longitude, y = Latitude), alpha = .5, size = .7, color = &quot;green&quot; ) A higher zoom number leads to more detail. # d) TwinCities2 &lt;- get_stamenmap( bbox = c(left = -94.5, bottom = 44.3, right = -91.94, top = 45.5), maptype = &quot;watercolor&quot;, zoom = 10 ) ggmap(TwinCities2) + geom_point( data = Starbucks, aes(x = Longitude, y = Latitude), alpha = .7, size = 1, color = &quot;#00704A&quot; ) # e) ggmap(TwinCities) + geom_point( data = Starbucks, aes(x = Longitude, y = Latitude), alpha = .7, size = 1, color = &quot;#00704A&quot; ) + annotate( geom = &quot;point&quot;, x = -93.1712321, y = 44.9378965, color = &quot;orange&quot; ) + annotate( geom = &quot;text&quot;, x = -93.1712321, y = 44.91, color = &quot;darkorange&quot;, label = &quot;MAC&quot; ) + theme_map() + theme(legend.background = element_blank()) Contour Maps The geom_density_2d and stat_density_2d functions are great for plotting distributions over spatial regions. Here is an example that shows the densities of Starbucks in the North America. US_map2 &lt;- get_stamenmap( bbox = c(left = -132, bottom = 20, right = -65, top = 55), maptype = &quot;terrain&quot;, zoom = 4 ) ggmap(US_map2) + geom_density_2d(data = Starbucks, aes(x = Longitude, y = Latitude), size = 0.3) + stat_density_2d( data = Starbucks, aes(x = Longitude, y = Latitude, fill = ..level.., alpha = ..level..), size = 0.1, bins = 20, geom = &quot;polygon&quot; ) + scale_alpha(guide = &#39;none&#39;) + scale_fill_gradient( low = &quot;green&quot;, high = &quot;red&quot;, guide = &#39;none&#39; ) Choropleths Geographical data needn’t be expressed by latitude and longitude. For choropleth maps, instead of visualizing our data as points with different aesthetics (size, color, transparency, etc.), we color different regions (or mathematically, polygons) on the maps based on data values. To do this we need to specify both the geometric regions on which the data resides (counties, states, zip codes, etc.), and then wrangle the data so that there is one value per region. Let’s return to the Starbucks data. First, we will create a new dataset, starbucks_us_by_state that limits the data to the US, finds the number of Starbucks in each state, and creates a state name that is in all lowercase letters that matches the state name in the region variable of the states_map dataset. The states_map dataset gives information about creating the borders of the US states. The data is retrieved using the map_data() function. Run ?map_data in the console to see more information about what other maps are available. There are also other packages that provide different types of maps. Then, we can use geom_map() to create a choropleth map. Let’s take a look at the map and we’ll go through the details after. # Create a new Starbucks dataset that # - filters to the US # - summarizes the number of Starbucks in each state # - has full names of states in lowercase letters (to match to states_map data created next) starbucks_us_by_state &lt;- Starbucks %&gt;% filter(Country == &quot;US&quot;) %&gt;% count(`State/Province`) %&gt;% mutate(state_name = str_to_lower(abbr2state(`State/Province`))) # US states map information - coordinates used to draw borders states_map &lt;- map_data(&quot;state&quot;) # map that colors state by number of Starbucks starbucks_us_by_state %&gt;% ggplot() + geom_map( map = states_map, aes( map_id = state_name, fill = n ) ) + # This assures the map looks decently nice: expand_limits(x = states_map$long, y = states_map$lat) + theme_map() Now, let’s look more closely at what each piece of the code below is doing. starbucks_us_by_state %&gt;% ggplot() + geom_map( map = states_map, aes( map_id = state_name, fill = n ) ) + expand_limits(x = states_map$long, y = states_map$lat) + theme_map() Choose a Map The map argument tells R at which level to create the map. Really, it tells it how to draw all the borders This is a very special data set. According to the geom_map() documentation, it is a “data frame that contains the map coordinates … It must contain columns x or long, y or lat, and region or id.” We are using the map_data() function to create the map file (see above for more details. You can open the map data, states_map, and see that it adheres to the rules. starbucks_us_by_state %>%&nbsp;&nbsp;ggplot() +&nbsp;&nbsp;geom_map(&nbsp;&nbsp;&nbsp;&nbsp;map = states_map,&nbsp;&nbsp;&nbsp;&nbsp;aes(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;map_id = state_name,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fill = n&nbsp;&nbsp;&nbsp;&nbsp;)&nbsp;&nbsp;) +&nbsp;&nbsp;expand_limits(x = states_map$long, y = states_map$lat) +&nbsp;&nbsp;theme_map() Connect Map ID/Region Variable to Data Being Plotted The map_id inside of aes() is a required aesthetic for the geom_map() geom. It tells R which variable is the region/id variable, in this case the state. It connects the region or id from the map (region variable in states_map dataset, in this example) to the dataset being plotted (state_name in starbucks_us_by_state, in this example). So state_name needs to have the same form as region, which is why we modified the state names in starbucks_us_by_state. starbucks_us_by_state %>%&nbsp;&nbsp;ggplot() +&nbsp;&nbsp;geom_map(&nbsp;&nbsp;&nbsp;&nbsp;map = states_map,&nbsp;&nbsp;&nbsp;&nbsp;aes(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;map_id = state_name,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fill = n&nbsp;&nbsp;&nbsp;&nbsp;)&nbsp;&nbsp;) +&nbsp;&nbsp;expand_limits(x = states_map$long, y = states_map$lat) +&nbsp;&nbsp;theme_map() Use ggplot2 Features We tell it to fill in the states by the variable n, the number of Starbucks in each state. With the geom_map() geom, it will fill in the borders of the regions we defined in the map argument. starbucks_us_by_state %>%&nbsp;&nbsp;ggplot() +&nbsp;&nbsp;geom_map(&nbsp;&nbsp;&nbsp;&nbsp;map = states_map,&nbsp;&nbsp;&nbsp;&nbsp;aes(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;map_id = state_name,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fill = n&nbsp;&nbsp;&nbsp;&nbsp;)&nbsp;&nbsp;) +&nbsp;&nbsp;expand_limits(x = states_map$long, y = states_map$lat) +&nbsp;&nbsp;theme_map() expand_limits() Use expand_limits() to assure that the map covers the entire area it’s supposed to. We put the longitude variable from states_map for the x argument and the latitude variable from states_map for the y argument to assure the map stretches across the entire range of longitudes and latitudes in the map. starbucks_us_by_state %>%&nbsp;&nbsp;ggplot() +&nbsp;&nbsp;geom_map(&nbsp;&nbsp;&nbsp;&nbsp;map = states_map,&nbsp;&nbsp;&nbsp;&nbsp;aes(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;map_id = state_name,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fill = n&nbsp;&nbsp;&nbsp;&nbsp;)&nbsp;&nbsp;) +&nbsp;&nbsp;expand_limits(x = states_map$long, y = states_map$lat) +&nbsp;&nbsp;theme_map() theme_map() This is a personal preference, but theme_map() often makes the map look nicer. starbucks_us_by_state %>%&nbsp;&nbsp;ggplot() +&nbsp;&nbsp;geom_map(&nbsp;&nbsp;&nbsp;&nbsp;map = states_map,&nbsp;&nbsp;&nbsp;&nbsp;aes(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;map_id = state_name,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fill = n&nbsp;&nbsp;&nbsp;&nbsp;)&nbsp;&nbsp;) +&nbsp;&nbsp;expand_limits(x = states_map$long, y = states_map$lat) +&nbsp;&nbsp;theme_map() Add ggplot2 Layers You can add any of the ggplot2 layers on top of this map. In this example, we’ve added MN Starbucks as points, included a title, and changed the legend background (so it doesn’t have one). starbucks_us_by_state %&gt;% ggplot() + geom_map( map = states_map, aes( map_id = state_name, fill = n ) ) + geom_point( data = Starbucks %&gt;% filter(`State/Province` == &quot;MN&quot;), aes(x = Longitude, y = Latitude), size = 0.05, alpha = 0.2, color = &quot;goldenrod&quot; ) + expand_limits(x = states_map$long, y = states_map$lat) + labs(title = &quot;Starbucks in MN&quot;) + theme_map() + theme(legend.background = element_blank()) Resources Prof. Lendway’s demo video ggplot2 documentation Example by Arie Voorman (some things could be out of date since it’s from 2015) Alternative Methods There are plenty of other methods available to make choropleths in R. Let’s demonstrate just three additional methods with data on the 2016 U.S. presidential election results by county: elect &lt;- read_csv(&quot;https://www.macalester.edu/~ajohns24/data/electionDemographics16.csv&quot;) # reformat the FIPS region codes elect &lt;- elect %&gt;% mutate(fips = ifelse(region &lt; 10000, paste(&quot;0&quot;, as.character(region), sep = &quot;&quot;), as.character(region))) # define appropriate (&amp; nicely labeled) breaks elect$brk &lt;- cut(elect$perrep_2016, breaks = seq(0, 100, by = 10), labels = c( &quot;0-9&quot;, &quot;10-19&quot;, &quot;20-29&quot;, &quot;30-39&quot;, &quot;40-49&quot;, &quot;50-59&quot;, &quot;60-69&quot;, &quot;70-79&quot;, &quot;80-89&quot;, &quot;90-100&quot; ), include.lowest = TRUE ) First, we will load a map of the counties in the United States: county_map &lt;- socviz::county_map # from socviz library mapping_data &lt;- elect %&gt;% rename(id = fips) %&gt;% left_join(county_map, by = &quot;id&quot;) Now here is the map with the method from above, using ggplot + geom_map: ggplot(elect) + geom_map(data = elect, map = county_map, aes(map_id = fips, fill = brk)) + scale_fill_manual(values = rev(brewer.pal(10, &quot;RdBu&quot;)), name = &quot;Percent Republican&quot;) + expand_limits(x = county_map$long, y = county_map$lat) + theme_map() + theme(legend.position = &quot;right&quot;) Alternative 1: ggplot + geom_polygon ggplot(mapping_data, aes(x = long, y = lat, fill = perrep_2016, group = group)) + coord_equal() + geom_polygon(color = NA) + scale_fill_gradientn(name = &quot;Percent Republican&quot;, colours = c(&quot;blue&quot;, &quot;purple&quot;, &quot;red&quot;), values = scales::rescale(seq(0, 100, by = 10))) + theme_map() + theme(legend.position = &quot;right&quot;) Alternative 2: plot_usmap # This function is in the usmap package plot_usmap(data = elect, values = &quot;brk&quot;, color = NA, exclude = &quot;AK&quot;) + scale_fill_manual(values = rev(brewer.pal(10, &quot;RdBu&quot;)), name = &quot;Percent Republican&quot;) + theme(legend.position = &quot;right&quot;) Exercise: Even More with Starbucks The example above did not account for population of each state in the map. In the code below, a new variable is created, starbucks_per_10000, that gives the number of Starbucks per 10,000 people. It is in the starbucks_with_2018_pop_est dataset. Here is a link to the data census_pop_est_2018 &lt;- read_csv(&quot;https://bcheggeseth.github.io/112_fall_2022/data/us_census_2018_state_pop_est.csv&quot;) %&gt;% separate(state, into = c(&quot;dot&quot;, &quot;state&quot;), extra = &quot;merge&quot;) %&gt;% select(-dot) %&gt;% mutate(state = str_to_lower(state)) starbucks_with_2018_pop_est &lt;- starbucks_us_by_state %&gt;% left_join(census_pop_est_2018, by = c(&quot;state_name&quot; = &quot;state&quot;) ) %&gt;% mutate(starbucks_per_10000 = (n / est_pop_2018) * 10000) Exercise 6.2 Create a choropleth state map that shows the number of Starbucks per 10,000 people on a map of the US. Use a new fill color, add points for all Starbucks in the continental US, add an informative title for the plot, and include a caption that says who created the plot (you!). Make a conclusion about what you observe. Dynamnic Maps with leaflet Leaflet is an open-source JavaScript library for creating maps. It can be used outside of R, but we will only discuss using the leaflet library in R. This library uses a different plotting framework from ggplot2 although it still has a tidyverse feel due to its use of the pipe, %&gt;% and the way it adds layers to the plot, just like in ggplot2. Steps to Create a Map Create a map widget by calling leaflet() and telling it the data to use. Add a base map using addTiles() (the default) or addProviderTiles(). Add layers to the map by using layer functions (e.g. , addMarkers(), addPolygons()) to modify the map widget. Repeat step 3 as desired. Print the map widget to display it. Creating a Map with Markers/Points Below, we create a basic map and add points of interest (the points are a layer on the map). The data are in favorite_stp, created below. The function we will use to create the maps will look for certain variable names for latitude (lat, latitude) and longitude (lng, long, or longitude). If you do not name them one of those things or if the data you are using doesn’t name them that, you need to call out the name explicitly (you’ll see that next). You can use a “two-finger scroll” to zoom in and out. # Brianna&#39;s favorite St. Paul places - Used Google Maps to get coordinates # https://support.google.com/maps/answer/18539?hl=en&amp;co=GENIE.Platform%3DDesktop favorite_stp &lt;- tibble( place = c( &quot;Macalester College&quot;, &quot;Groveland Recreation Center&quot;, &quot;Due Focacceria&quot;, &quot;Shadow Falls Park&quot;, &quot;Mattocks Park&quot;, &quot;Carondelet Fields&quot;, &quot;Pizza Luce&quot;, &quot;Cold Front Ice Cream&quot; ), long = c( -93.1712321, -93.1851310, -93.1775469, -93.1944518, -93.171057, -93.1582673, -93.1524256, -93.156652 ), lat = c( 44.9378965, 44.9351034, 44.9274973, 44.9433359, 44.9284142, 44.9251236, 44.9468848, 44.9266768 ) ) leaflet(data = favorite_stp) %&gt;% # base plot addTiles() %&gt;% # base map - default is openstreet map addMarkers() # Adds markers - knows lat and long from names in data The graph below is the same as above, but the code explicitly specifies latitude and longitude, which you would need to do if those variables had a name not recognized by the function, and adds labels. WARNING: DO NOT FORGET THE ~ BEFORE THE VARIABLE NAMES!!! leaflet(data = favorite_stp) %&gt;% addTiles() %&gt;% addMarkers( lng = ~long, lat = ~lat, label = ~place ) We can change just about everything about our map. The plot below is the same plot as above with some aesthetic changes: We changed the base map with addProviderTiles(). To see all available provider base maps, type providers in the console. To access those maps, use providers$PROVIDERNAME inside the addProviderTiles() function, where PROVIDERNAME is one of those listed providers. When you type provider$ a list should show up that you can click on. We changed the marker type by using addCircles() instead of addMarkers() - Search addControl in the Help or type ?addControl into the console to see what all the arguments mean and how you can change them. All variable arguments are preceded with a tilde, ~. The weight argument tells it how thick to make the lines or points, pixels. The opacity argument is the transparency, like the alpha argument in ggplot2. Colors need to be in “hex” form. We used the col2hex() function from the gplots library to do that. The colors also need to be valid R colors. leaflet(data = favorite_stp) %&gt;% addProviderTiles(providers$Stamen.Watercolor) %&gt;% addCircles( lng = ~long, lat = ~lat, label = ~place, weight = 10, opacity = 1, color = col2hex(&quot;darkblue&quot;) ) The map below is also the “same” as the ones above, but with a new base map and a line to trace a route, which was created with the addPolylines() layer. It traces the locations in the order they are entered in the dataset. leaflet(data = favorite_stp) %&gt;% addProviderTiles(providers$CartoDB.DarkMatter) %&gt;% addCircles( lng = ~long, lat = ~lat, label = ~place, weight = 10, opacity = 1, color = col2hex(&quot;darkred&quot;) ) %&gt;% addPolylines( lng = ~long, lat = ~lat, color = col2hex(&quot;darkred&quot;) ) Choropleth Layers with addPolygons() For making maps with borders (like choropleth maps), the functions can receive the base maps with spatial data a few different ways. In the example here, we use functions from the sf package to get the data in the right form. In the demo video listed under Resources below, a data.frame is translated to an sf object. Hopefully those two sets of instructions fit most of the cases you are interested in. In the code chunk below, the function st_read() downloads the shape file for the counties of North Carolina, which is included in the sf package. # North Carolina births and sids deaths nc &lt;- st_read(system.file(&quot;shape/nc.shp&quot;, package = &quot;sf&quot;), quiet = TRUE ) %&gt;% mutate(sid_per_1000birth_79 = SID79 / BIR79 * 1000) # Compute centroid (center) of each county county_centroid_lat_long &lt;- as_tibble(st_coordinates(st_centroid(nc))) %&gt;% rename( centr_long = X, centr_lat = Y ) # County names and sid_per_1000birth_79 nc_centroid_county &lt;- st_drop_geometry(nc) %&gt;% select(NAME, sid_per_1000birth_79) # All centroid level info nc_centroid &lt;- county_centroid_lat_long %&gt;% bind_cols(nc_centroid_county) The dataset has number of births and number of SIDS cases in each county of North Carolina from 1974-1979 and 1979-1984. We computed a variable called sid_per_1000birth_79 which is the number of SIDS cases per 1000 births in 1979. Below, the the NAMES and geometry variables from the first five rows of the data are printed out. The geometry variable contains information about how to plot the boundaries of the counties. Open the dataset and examine the geometry variable. The leaflet function knows that the geometry variable contains this special information. nc %&gt;% select(NAME, geometry) %&gt;% slice(1:5) ## Simple feature collection with 5 features and 1 field ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -81.74107 ymin: 36.07282 xmax: -75.77316 ymax: 36.58965 ## Geodetic CRS: NAD27 ## NAME geometry ## 1 Ashe MULTIPOLYGON (((-81.47276 3... ## 2 Alleghany MULTIPOLYGON (((-81.23989 3... ## 3 Surry MULTIPOLYGON (((-80.45634 3... ## 4 Currituck MULTIPOLYGON (((-76.00897 3... ## 5 Northampton MULTIPOLYGON (((-77.21767 3... To learn more about the data type nc into the Help menu or ?nc into the console. This plot puts the map with North Carolina county borders on top of the Open Street Map. This map isn’t that interesting by itself. leaflet(nc) %&gt;% addTiles() %&gt;% addPolygons() Now, let’s use some of the data to enhance the graph by creating a choropleth map where we color the counties by sid_per_1000birth_79. In ggplot(), we can map a variable to color or fill inside the aesthetic, but in the leaflet functions we cannot do this. Instead, we need to create a variable of hex color names that tells it how to color or fill. Thankfully, there are functions that help us do that! Let’s walk through the detail of how we created the graph below. # creates a function that can be used to map a variable to # the color palette using viridis pal &lt;- colorNumeric(&quot;viridis&quot;, domain = nc$sid_per_1000birth_79 ) leaflet(nc) %&gt;% addTiles() %&gt;% addPolygons( fillColor = ~ pal(sid_per_1000birth_79), # fills according to that variable fillOpacity = 0.7 ) # like alpha in ggplot The colorNumeric() function returns a function that maps a variable’s values to colors in the given palette, in this case “viridis”. So, pal() is a function. We can then use that function inside addPolygons(). If we apply the function to the sid_per_1000birth_79 variable, it returns a variable of hex colors and the variable of colors is used to fill the counties. Below we print out what happens when pal() is applied to sid_per_1000birth_79. We can see that it returns hex colors. So, the variable in the fillColor argument inside addPolygons() above, is a variable of hex color names. head(pal(nc$sid_per_1000birth_79)) ## [1] &quot;#440154&quot; &quot;#C0DF25&quot; &quot;#38588C&quot; &quot;#2A778E&quot; &quot;#34618D&quot; &quot;#26828E&quot; Again, this is different from ggplot(), where we could map a variable to color or fill and it would do the translating of variable to color scale for us. In the leaflet functions, we have to explicitly provide the colors in a variable. The colorNumeric() command helps you do that. colorBin(), colorQuantile(), and colorFactor() are other functions you might need to use depending on the type of variable you are trying to map to colors. There are many customizeable options in leaflet, much like ggplot(). Here is a commented set of code to point out some useful functions and arguments: # creates a function that can be used to map a variable to # the color palette using viridis pal &lt;- colorNumeric(&quot;viridis&quot;, domain = nc$sid_per_1000birth_79 ) leaflet(nc) %&gt;% addTiles() %&gt;% addPolygons( # skips drawing the borders: stroke = FALSE, # fills according to variable of hex colors: fillColor = ~ pal(sid_per_1000birth_79), # changes transparency, like alpha in ggplot fillOpacity = 0.7, # how much to simplify the plot when zooming: smoothFactor = 0.5, # changes what happens to the shape when we mouse over it highlight = highlightOptions( weight = 5, color = &quot;black&quot;, fillOpacity = 0.9, bringToFront = FALSE ) ) %&gt;% addCircles( data = nc_centroid, lng = ~centr_long, lat = ~centr_lat, # label that appears when you click on the marker, # in this case county name and sid_per_1000birth_79 # rounded to the 2nd decimal popup = ~ paste(NAME, &quot;: &quot;, round(sid_per_1000birth_79, 2), sep = &quot;&quot; ), radius = 2 ) %&gt;% # Add a legend addLegend( pal = pal, values = ~sid_per_1000birth_79, opacity = 0.5, title = NULL, position = &quot;bottomright&quot; ) ## Error in get(&quot;.xts_chob&quot;, .plotxtsEnv): object &#39;.xts_chob&#39; not found Resources Prof. Lendway’s introductory video Prof. Lendway’s demo video Detailed leaflet documenation (with examples) leaflet cheat sheet Provider map previews Tutorial by Andrew Ba Tran, investigative data reporter at Washington Post Exercise: Favorite Places Exercise 6.3 In this exercise, you are going to create a single map of some of your favorite places! The end result will be one map. Create a data set using the tibble() function that has 10-15 rows of your favorite places. The columns will be the name of the location, the latitude, the longitude, and a column that indicates if it is in your top 3 favorite locations or not. For an example of how to use tibble(), look at the favorite_stp that is created manually above. Create a map that uses circles to indicate your favorite places. Label them with the name of the place. Choose the base map you like best. Color your 3 favorite places differently than the ones that are not in your top 3. Add a legend that explains what the colors mean. If there are other variables you want to add that could enhance your plot, do that now. You could also connect all your locations together with a line in a meaningful way (you may need to order them differently in the original data). "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
