[["index.html", "COMP/STAT 112: Introduction to Data Science Welcome!", " COMP/STAT 112: Introduction to Data Science Welcome! Data icons created by Kiranshastry - Flaticon Note: This site is still in construction! This is the day-to-day course site for Introduction to Data Science (COMP/STAT 112) at Macalester College for Fall 2022. The activities here were developed by a variety of faculty in the MSCS Department at Macalester College. This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],["course-schedule.html", "Course Schedule", " Course Schedule The schedule below is a tentative outline of our plans for the semester. Before each class period, please watch/read the indicated videos/readings and check on your understanding by actively reviewing the associated Learning Goals. Week 1 Date Activity Topic & Assignments Optional Readings/Videos 8/31 1 Intro to R, RStudio, and R Markdown Slides for Today Assignment 1 Due Tuesday, September 6 at 11:59pm Readings: Introduction to R Markdown, by Wickham and Grolemund Tidy Data, by Wickham Tidy Data (12.1, 12.2), by Wickham and Grolemund Videos: Setting up for success in the course, by Lisa Lendway Introduction to RStudio, by Alicia Johnson Check version of R and RStudio, by Lisa Lendway RStudio tour, by Lisa Lendway R Markdown introduction, by Lisa Lendway 9/2 Friday Fun: Community Building Scavenger Hunt Finish Assignment 1 (due 9/6). Week 11 Date Activity Topic Content: Videos/Readings Class Materials: Slides/Notes 4/5 Spatial: Catch up Day Slides Board Notes 4/7 Content Conversation 2 (Sign up for a slot here) Work on Spatial Mini Project, due 4/12 Week 12 Date Activity Topic Content: Videos/Readings Class Materials: Slides/Notes 4/12 Capstone Project Work 4/14 Capstone Project Work Finish Spatial Mini Project, due 4/12 Start Capstone Project, due 5/6 Week 13 Date Activity Topic Content: Videos/Readings Class Materials: Slides/Notes 4/19 Capstone Project Work 4/21 Capstone Project Work Continue with Capstone Project, due 5/6 Week 14 Date Activity Topic Content: Videos/Readings Class Materials: Slides/Notes 4/26 Capstone Project Work 4/28 Capstone Project Work Continue with Capstone Project, due 5/6 Finals Week Date Activity Topic Content: Videos/Readings Class Materials: Slides/Notes Thurs 5/5: 1:30-3:30pm Section 2 Presentations Fri 5/6: 8-10am Section 1 Presentations FinishCapstone Project, due 5/6 "],["learning-goals.html", "Learning Goals General Skills Course Topics", " Learning Goals The goal of this course is for you to gain confidence in carrying out the entire data science pipeline, from research question formulation, to data collection/scraping, to wrangling, to modeling, to visualization, to presentation and communication Specific course topics and general skills are listed below. General Skills Data Communication In written and oral formats: Inform and justify data cleaning and analysis process and the resulting conclusions with clear, organized, logical, and compelling details that adapt to the background, values, and motivations of the audience and context in which communication occurs. Collaborative Learning Understand and demonstrate characteristics of effective collaboration (team roles, interpersonal communication, self-reflection, awareness of social dynamics, advocating for yourself and others). Develop a common purpose and agreement on goals. Be able to contribute questions or concerns in a respectful way. Share and contribute to the group’s learning in an equitable manner. Develop a familiarity and comfort in using collaboration tools such as Git and Github. Course Topics Specific learning objectives for our course topics are listed below. Use these to guide your synthesis of course material for specific topics. Note that the topics are covered in the order of the data science pipeline, not the order in which we will cover them in class. Foundation Intro to R, RStudio, and R Markdown Download and install the necessary tools (R, RStudio) Develop comfort in navigating the tools in RStudio Develop comfort in writing and knitting a R Markdown file Identify the characteristics of tidy data Use R code: as a calculator and to explore tidy data Data Acquisition Data Import and Basic Cleaning stuff Data Scraping (rvest) stuff APIs stuff SQL stuff Data Wrangling Six main verbs stuff spread/gather stuff join stuff factors stuff mini-project stuff Data Visualization The learning goals may be adjusted before we start the material of this section. Introduction to Data Visualization Understand the Grammar of Graphics Use ggplot2 functions to create basic layers of graphics Understand the different basic univariate visualizations for categorical and quantiative variables Effective Visualization Understand and apply the guiding principles of effective visualizations Bivariate Identify appropriate types of bivariate visualizations, depending on the type of variables (categorical, quantitative) Create basic bivariate visualizations based on real data with ggplot2 functions Multivariate Understand how we can use additional aesthetics such as color and size to incorporate a third (or more variables) to a bivariate plot with ggplot2 functions Develop comfort with creating and interpreting heat maps and star plots, which allow you to look for patterns in variation in many variables. Spatial Plot data points on top of a map using the ggmap() function along with ggplot2 functions Create choropleth maps using geom_map() Add points and other ggplot2 features to a map created from geom_map() Understand the basics of creating a map using leaflet, including adding points and choropleths to a base map Network and Interactive stuff Shiny stuff Tables stuff Data Modeling The learning goals may be adjusted before we start the material of this section. EDA stuff Text Analysis stuff Project Presentations &amp; Communication The learning goals may be adjusted before we start the material of this section. Oral Communication stuff Written Communication stuff "],["intro-to-r-rstudio-and-r-markdown.html", "Topic 1 Intro to R, RStudio, and R Markdown Learning Goals Getting Started in RStudio R Markdown and Reproducible Research Practice", " Topic 1 Intro to R, RStudio, and R Markdown Learning Goals Download and install the necessary tools (R, RStudio) Develop comfort in navigating the tools in RStudio Develop comfort in writing and knitting a R Markdown file Identify the characteristics of tidy data Use R code: as a calculator and to explore tidy data Getting Started in RStudio As you might guess from the name, “Data Science” requires data. Working with modern (large, messy) data sets requires statistical software. We’ll exclusively use RStudio. Why? it’s free it’s open source (the code is free &amp; anybody can contribute to it) it has a huge online community (which is helpful for when you get stuck) it’s one of the industry standards it can be used to create reproducible and lovely documents (In fact, the course materials that you’re currently reading were constructed entirely within RStudio!) Download R &amp; RStudio To get started, take the following two steps in the given order. Even if you already have R/RStudio, make sure to update to the most recent versions. Download and install the R statistical software at https://mirror.las.iastate.edu/CRAN/ Download and install the FREE version of RStudio at https://www.rstudio.com/products/rstudio/download/#download What’s the difference between R and RStudio? Mainly, RStudio requires R – thus it does everything R does and more. We will be using RStudio exclusively. A quick tour of RStudio Open RStudio! You should see four panes, each serving a different purpose: Figure 1.1: RStudio Interface This short video tour of RStudio summarizes some basic features of the console. Exercise 1.1 (Warm Up) Use RStudio as a simple calculator to do the following: Perform a simple calculation: calculate 90/3. RStudio has built-in functions to which we supply the necessary arguments: function(arguments). Use the built-in function sqrt to calculate the square root of 25. Use the built-in function rep to repeat the number “5” eight times. Use the seq function to create the vector (0, 3, 6, 9, 12). (The video doesnt cover this!) Create a new vector by concatenating three repetitions of the vector from the previous part. Solution 90/3 ## [1] 30 sqrt(25) ## [1] 5 rep(5, times = 8) ## [1] 5 5 5 5 5 5 5 5 seq(0, 12, by = 3) ## [1] 0 3 6 9 12 rep(seq(0, 12, by = 3), times = 3) ## [1] 0 3 6 9 12 0 3 6 9 12 0 3 ## [13] 6 9 12 rep(seq(0, 12, by = 3), each = 3) #notice the difference between times and each ## [1] 0 0 0 3 3 3 6 6 6 9 9 9 ## [13] 12 12 12 Exercise 1.2 (Assignment) We often want to store our output for later use (why?). The basic idea in RStudio: `name &lt;- output` Copy and paste the following code into the console, line by line. NOTE: RStudio ignores any content after the #. Thus we use this to ‘comment’ and organize our code. #type square_3 square_3 #calculate 3 squared 3^2 #store this as &quot;square_3&quot; square_3 &lt;- 3^2 #type square_3 again! square_3 #do some math with square_3 square_3 + 2 Tidy Data Not only does “Data Science” require statistical software, it requires DATA! Consider the Google definition: Figure 1.2: A datum. With this definition in mind, which of the following are examples of data? tables ## family father mother sex height nkids ## 1 1 78.5 67.0 M 73.2 4 ## 2 1 78.5 67.0 F 69.2 4 ## 3 1 78.5 67.0 F 69.0 4 ## 4 1 78.5 67.0 F 69.0 4 ## 5 2 75.5 66.5 M 73.5 4 ## 6 2 75.5 66.5 M 72.5 4 photo video text / tweets We’ll mostly work with data that look like this: ## family father mother sex height nkids ## 1 1 78.5 67.0 M 73.2 4 ## 2 1 78.5 67.0 F 69.2 4 ## 3 1 78.5 67.0 F 69.0 4 ## 4 1 78.5 67.0 F 69.0 4 ## 5 2 75.5 66.5 M 73.5 4 ## 6 2 75.5 66.5 M 72.5 4 This isn’t as restrictive as it seems. How can we convert the above signals, photos, videos, and text to a data table format? Example: After a scandal among FIFA officials, fivethirtyeight.com posted an analysis of FIFA viewership, “How to Break FIFA”. Here’s a snapshot of the data used in this article: country confederation population_share tv_audience_share gdp_weighted_share United States CONCACAF 4.5 4.3 11.3 Japan AFC 1.9 4.9 9.1 China AFC 19.5 14.8 7.3 Germany UEFA 1.2 2.9 6.3 Brazil CONMEBOL 2.8 7.1 5.4 United Kingdom UEFA 0.9 2.1 4.2 Italy UEFA 0.9 2.1 4.0 France UEFA 0.9 2.0 4.0 Russia UEFA 2.1 3.1 3.5 Spain UEFA 0.7 1.8 3.1 The data table above is in tidy format. Tidy data tables have three key features: Each row represents a unit of observation. Each column represents a variable (ie. an attribute of the cases that can vary from case to case). Each variable is one of two types: quantitative = numerical categorical = discrete possibilities/categories Each entry contains a single data value; no analysis, summaries, footnotes, comments, etc., and only one value per cell Exercise 1.3 (Units of Observation and Variables) Consider the following in a group: What are the units of observation in the FIFA data? What are the variables? Which are quantitative? Which are categorical? Are these tidy data? Solution a. A FIFA member country b. country name, soccer or football confederation, country&#39;s share of global population (percentage), country&#39;s share of global world cup TV Audience (percentage), country&#39;s GDP-weighted audience share (percentage) c. Yes Exercise 1.4 (Tidy vs. Untidy) Check out the following data. Explain to each other why they are untidy and how we can tidy them. Data 1: FIFA country confederation population share tv_share United States CONCACAF i don’t know* 4.3% *look up later Japan AFC 1.9 4.9% China AFC 19.5 14.8% total=24% Data 2: Gapminder life expectancies by country country 1952 1957 1962 Asia Afghanistan 28.8 30.3 32.0 Bahrain 50.9 53.8 56.9 Africa Algeria 43.0 45.7 48.3 Solution a. There are notes such as &quot;I don&#39;t know&quot; and &quot;look up later&quot; in columns with numeric values; the last row with the total is a summary. We could remove the text notes, replace it with the value if known, and remove the last row with the total summary. b. The first column does not have a row name. It should be continent. Additionally, Bahrain needs a value for the continent. Data Basics in RStudio For now, we’ll focus on tidy data. In a couple of weeks, you’ll learn how to turn untidy data into tidy data. Exercise 1.5 (Importing Package Data) The first step to working with data in RStudio is getting it in there! How we do this depends on its format (eg: Excel spreadsheet, csv file, txt file) and storage locations (eg: online, within Wiki, desktop). Luckily for us, the fifa_audience data are stored in the fivethirtyeight RStudio package. Copy and paste the following code into the Console and press Enter. #load the fivethirtyeight package library(fivethirtyeight) #load the fifa data data(&quot;fifa_audience&quot;) #store this under a shorter, easier name fifa &lt;- fifa_audience Exercise 1.6 (Examining Data Structures) Before we can analyze our data, we must understand its structure. Try out the following functions (copy and paste into the Console). For each, make a note that describes its action. #(what does View do?) View(fifa) #(what does head do?) head(fifa) #(what does dim do?) dim(fifa) #(what does names do?) names(fifa) Solution #View() opens up a new tab with a spread sheet preview of the data to visually explore the data. It is commented out in the Rmarkdown file because this is an interactive feature #View(fifa) #head() gives the first 6 (default number) rows of a data set head(fifa) ## # A tibble: 6 × 5 ## country confederation population_share ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 United… CONCACAF 4.5 ## 2 Japan AFC 1.9 ## 3 China AFC 19.5 ## 4 Germany UEFA 1.2 ## 5 Brazil CONMEBOL 2.8 ## 6 United… UEFA 0.9 ## # … with 2 more variables: ## # tv_audience_share &lt;dbl&gt;, ## # gdp_weighted_share &lt;dbl&gt; #dim() gives the number of rows and number of columns dim(fifa) ## [1] 191 5 #names() gives the names of the columns/variables names(fifa) ## [1] &quot;country&quot; ## [2] &quot;confederation&quot; ## [3] &quot;population_share&quot; ## [4] &quot;tv_audience_share&quot; ## [5] &quot;gdp_weighted_share&quot; Exercise 1.7 (Codebooks) Data are also only useful if we know what they measure! The fifa data table is tidy – it doesn’t have any helpful notes. Rather, information about the data is stored in a separate codebook. Codebooks can be stored in many ways (eg: Google docs, word docs, etc). Here the authors have made their codebook available in RStudio (under the original fifa_audience name). Check it out (run the following code in the console): ?fifa_audience What does population_share measure? What are the units of population_share? Solution a. Country&#39;s share of global population b. Percentage between 0 and 100   Exercise 1.8 (Examining a Single Variable) Consider the following: We might want to access and focus on a single variable. To this end, we can use the $ notation: fifa$tv_audience_share fifa$confederation It’s important to understand the format/class of each variable (quantitative, categorical, date, etc) in both its meaning and its structure within RStudio: class(fifa$tv_audience_share) class(fifa$confederation) If a variable is categorical (either in character or factor format), we can determine its levels / category labels: levels(fifa$confederation) levels(factor(fifa$confederation)) R Markdown and Reproducible Research Reproducible research is the idea that data analyses, and more generally, scientific claims, are published with their data and software code so that others may verify the findings and build upon them. - Reproducible Research, Coursera Useful Resources: R Markdown Quick Tour R Markdown Cheatsheet or in RStudio: Go to Help &gt; Cheat Sheets &gt; R Markdown Cheat Sheet R Markdown Reference Guide or in RStudio: Go to Help &gt; Cheat Sheets &gt; R Markdown Reference Guide Research often makes claims that are difficult to verify. A recent study of published psychology articles found that less than half of published claims could be reproduced. One of the most common reasons claims cannot be reproduced is confusion about data analysis. It may be unclear exactly how data was prepared and analyzed, or there may be a mistake in the analysis. In this course we will use an innovative format called R Markdown that dramatically increases the transparency of data analysis. R Markdown interleaves data, R code, graphs, tables, and text, packaging them into an easily publishable format. To use R Markdown, you will write an R Markdown formatted file in RStudio and then ask RStudio to knit it into an HTML document (or occasionally a PDF or MS Word document). Exercise 1.9 (Deduce the R Markdown Format) Look at this Sample RMarkdown and the HTML webpage it creates. Consider the following and discuss: How are bullets, italics, and section headers represented in the R Markdown file? How does R code appear in the R Markdown file? In the HTML webpage, do you see the R code, the output of the R code, or both? Solution Bullets are represented with * and + Italics are represented with * before and after a word or phrase Section headers are represented with # R code chunks are between 3 tick marks at the beginning and end; it is R code if there is an r in curly braces If echo=FALSE in curly braces, the code is not shown. Otherwise, both code and output are shown by default.   Now take a look at the R Markdown Cheatsheet. Look up the R Markdown features from the previous question on the cheatsheet. There’s a great deal more information there. Practice Complete the following. If you get stuck along the way, refer to the R Markdown Cheatsheet linked above, search the web for answers, and/or ask for help! Exercise 1.10 (Your First R Markdown File) Create a new R Markdown about your favorite food. Create a new file in RStudio (File -&gt; New File -&gt; R Markdown) called First_Markdown. Make sure you can compile (Knit) the Markdown into a webpage (html file). Add a new line between title and output that reads: author: Your Name. Create a brief essay about your favorite food. Make sure to include: A picture from the web A bullet list A numbered list Compile the document into an html file. Exercise 1.11 (New Data!) There’s a data set named comic_characters in the fivethirtyeightdata package. Check out the codebook (hint: use ?) to understand what these data measure. Then add a second section to your R Markdown file, and then use code chunks and R commands to perform/answer the following tasks/questions: Load the data. What are the units of observation? How many observations are there? In a new code chunk, print out the first 12 rows of the data set. Get a list of all variable names. What’s the class of the date variable? List all of the unique entries in the gsm variable (no need to include NA). Compile the document into an html file. "],["spatial-visualization.html", "Topic 2 Spatial Visualization Learning Goals Motivation Plotting Points on a Map Contour Maps Choropleths Dynamnic Maps with leaflet", " Topic 2 Spatial Visualization Learning Goals Plot data points on top of a map using the ggmap() function along with ggplot2 functions Create choropleth maps using geom_map() Add points and other ggplot2 features to a map created from geom_map() Understand the basics of creating a map using leaflet, including adding points and choropleths to a base map You can download a template .Rmd of this activity here. Motivation Take a look at these to get motivated/inspired to make your own: NYT article on effects of redlining NY Times mayoral primaries flickr Super zip shiny app Plotting Points on a Map Starbucks Example The Starbucks data, compiled by Danny Kaplan, contains information about every Starbucks in the world at the time the data were collected. It includes the Latitude and Longitude of each location. Let’s start by using familiar plotting tools # Starbucks locations Starbucks &lt;- read_csv(&quot;https://www.macalester.edu/~ajohns24/data/starbucks.csv&quot;) ggplot(data = Starbucks) + geom_point(aes(x = Longitude, y = Latitude), alpha = 0.2, size = 0.2 ) ## Warning: Removed 1 rows containing missing ## values (geom_point). The point pattern probably looks familiar. To highlight the geographical nature of this scatterplot, we can superimpose the points on top of a map, using the ggmap() function from the ggmap library. NOTE: we used to be able to easily bring in Google maps. As of mid-2018, in order to bring those in, you need to have a registered API key. If you want to do that, see google_key in the help. Then, see the documentation for get_map(). We will bring in other types of maps since Google maps are harder to do now and require you to submit credit card information. Instead, we bring in a stamen map (there are others you could try, but we’ll stick with this). You can also take a look at stamen maps on their website. First, let’s look at an example. # Get the map information world &lt;- get_stamenmap( bbox = c(left = -180, bottom = -57, right = 179, top = 82.1), maptype = &quot;terrain&quot;, zoom = 2 ) # Plot the points on the map ggmap(world) + # creates the map &quot;background&quot; geom_point( data = Starbucks, aes(x = Longitude, y = Latitude), alpha = .3, size = 0.2 ) + theme_map() ## Warning: Removed 1 rows containing missing ## values (geom_point). Next, we will walk through the get_stamenmap() function arguments. The code below is what was used to get the world map information. get_stamenmap( bbox = c(left = -180, bottom = -57, right = 179, top = 82.1), maptype = &quot;terrain&quot;, zoom = 2 ) bbox get_stamenmap(&nbsp;&nbsp;bbox = c(left = -180, bottom = -57, right = 179, top = 82.1),&nbsp;&nbsp;maptype = \"terrain\",&nbsp;&nbsp;zoom = 2) The bbox argument tells it the minimum and maximum latitude and longitude points. So, left is the minimum longitude, right is the maximum longitude, bottom is the minimum latitude, and top is the maximum latitude. One helpful trick is to go to openstreetmap: zoom in on the area of interest, click export, and you will see all the values you need. You may have to modify them slightly, which you can do after your initial plot. maptype get_stamenmap(&nbsp;&nbsp;bbox = c(left = -180, bottom = -57, right = 179, top = 82.1),&nbsp;&nbsp;maptype = \"terrain\",&nbsp;&nbsp;zoom = 2) The maptype tells it the style of the map. Check out the different options by looking in the get_stamenmap help (type ?get_stamenmap in the console). zoom get_stamenmap(&nbsp;&nbsp;bbox = c(left = -180, bottom = -57, right = 179, top = 82.1),&nbsp;&nbsp;maptype = \"terrain\",&nbsp;&nbsp;zoom = 2) When you make a large area, you need to decrease the zoom, otherwise it will take too long to load. So, it’s a good idea to start with a small zoom and you can always make it bigger if you want. This might seem counter-intuitive at first. Think of the zoom level as the level of detail. So, smaller numbers show less detail and larger numbers more detail. A good trick is to go to the stamanmaps webpage and search for the location you are mapping. Then, in the URL, you can see the zoom number. For example, this link is a map of St. Paul: http://maps.stamen.com/#terrain/12/44.9531/-93.0904. Notice the number 12 next to /#terrain/. That means it is zoomed in at 12. ggmap() We save the the map information from get_stamenmap() to a named value and then use it in ggmap(): # Get the map informationworld get_stamenmap(&nbsp;&nbsp;bbox = c(left = -180, bottom = -57, right = 179, top = 82.1),&nbsp;&nbsp;maptype = \"terrain\",&nbsp;&nbsp;zoom = 2)# Plot the points on the mapggmap(world) + # creates the map \"background\"&nbsp;&nbsp;geom_point(&nbsp;&nbsp;&nbsp;&nbsp;data = Starbucks,&nbsp;&nbsp;&nbsp;&nbsp;aes(x = Longitude, y = Latitude),&nbsp;&nbsp;&nbsp;&nbsp;alpha = .3,&nbsp;&nbsp;&nbsp;&nbsp;size = 0.2&nbsp;&nbsp;) +&nbsp;&nbsp;theme_map() The ggmap() function will print the “background” map. Think of it as the providing the canvas on which we will plot. This takes the place of our usual ggplot(). ggmap(world) After that, we can use the geom_XXX() functions from ggplot2 that we are used to in order to put points, lines, etc. on top of the map. But, we need to remember to also provide the data we are using in the geom_XXX() function(s) we use since we do not have the ggplot() function in which to provide it. # Get the map informationworld &nbsp;&nbsp;bbox = c(left = -180, bottom = -57, right = 179, top = 82.1),&nbsp;&nbsp;maptype = \"terrain\",&nbsp;&nbsp;zoom = 2)# Plot the points on the mapggmap(world) + # creates the map \"background\"&nbsp;&nbsp;geom_point(&nbsp;&nbsp;&nbsp;&nbsp;data = Starbucks,&nbsp;&nbsp;&nbsp;&nbsp;aes(x = Longitude, y = Latitude),&nbsp;&nbsp;&nbsp;&nbsp;alpha = .3,&nbsp;&nbsp;&nbsp;&nbsp;size = 0.2&nbsp;&nbsp;) +&nbsp;&nbsp;theme_map() theme_map() The last line of the code is theme_map(). This is optional, but it often makes it look nice. # Get the map informationworld &nbsp;&nbsp;bbox = c(left = -180, bottom = -57, right = 179, top = 82.1),&nbsp;&nbsp;maptype = \"terrain\",&nbsp;&nbsp;zoom = 2)# Plot the points on the mapggmap(world) + # creates the map \"background\"&nbsp;&nbsp;geom_point(&nbsp;&nbsp;&nbsp;&nbsp;data = Starbucks,&nbsp;&nbsp;&nbsp;&nbsp;aes(x = Longitude, y = Latitude),&nbsp;&nbsp;&nbsp;&nbsp;alpha = .3,&nbsp;&nbsp;&nbsp;&nbsp;size = 0.2&nbsp;&nbsp;) +&nbsp;&nbsp;theme_map() ## Warning: Removed 1 rows containing missing ## values (geom_point). So, the final map as a world map as the background with points plotted on top that show the Starbucks locations. The points are 20 percent (0.2) of their usual size and have a transparency level of 0.3. Resources Prof. Lendway’s demo video Examples from ggmap maintainer David Kahle ggmap cheatsheet Exercise: More with Starbucks Exercise 2.1 Now it is your turn to work with the Starbucks data. Add an aesthetic to the world map that sets the color of the points according to the ownership type. What, if anything, can you deduce from this visualization? Construct a new map of Starbucks locations in the Twin Cities metro area (approximately the five county metro area). In the Twin Cities plot, play with the zoom number. What does it do? (just describe what it does - don’t actually include more than one map). Try a couple different map types (see get_stamenmap() in help and look at maptype). Include a map with one of the other map types. Add a point to the map that indicates Macalester College and label it appropriately. There are many ways you can do this, but it may be easiest with the annotate() function (see ggplot2 cheatsheet). Contour Maps The geom_density_2d and stat_density_2d functions are great for plotting distributions over spatial regions. Here is an example that shows the densities of Starbucks in the North America. US_map2 &lt;- get_stamenmap( bbox = c(left = -132, bottom = 20, right = -65, top = 55), maptype = &quot;terrain&quot;, zoom = 4 ) ggmap(US_map2) + geom_density_2d(data = Starbucks, aes(x = Longitude, y = Latitude), size = 0.3) + stat_density_2d( data = Starbucks, aes(x = Longitude, y = Latitude, fill = ..level.., alpha = ..level..), size = 0.1, bins = 20, geom = &quot;polygon&quot; ) + scale_alpha(guide = FALSE) + scale_fill_gradient( low = &quot;green&quot;, high = &quot;red&quot;, guide = FALSE ) ## Warning: Removed 10468 rows containing ## non-finite values (stat_density2d). ## Removed 10468 rows containing ## non-finite values (stat_density2d). ## Warning: It is deprecated to specify `guide = FALSE` to remove a guide. Please use `guide = &quot;none&quot;` instead. ## It is deprecated to specify `guide = FALSE` to remove a guide. Please use `guide = &quot;none&quot;` instead. Choropleths Geographical data needn’t be expressed by latitude and longitude. For choropleth maps, instead of visualizing our data as points with different aesthetics (size, color, transparency, etc.), we color different regions (or mathematically, polygons) on the maps based on data values. To do this we need to specify both the geometric regions on which the data resides (counties, states, zip codes, etc.), and then wrangle the data so that there is one value per region. Let’s return to the Starbucks data. First, we will create a new dataset, starbucks_us_by_state that limits the data to the US, finds the number of Starbucks in each state, and creates a state name that is in all lowercase letters that matches the state name in the region variable of the states_map dataset. The states_map dataset gives information about creating the borders of the US states. The data is retrieved using the map_data() function. Run ?map_data in the console to see more information about what other maps are available. There are also other packages that provide different types of maps. Then, we can use geom_map() to create a choropleth map. Let’s take a look at the map and we’ll go through the details after. # Create a new Starbucks dataset that # - filters to the US # - summarizes the number of Starbucks in each state # - has full names of states in lowercase letters (to match to states_map data created next) starbucks_us_by_state &lt;- Starbucks %&gt;% filter(Country == &quot;US&quot;) %&gt;% count(`State/Province`) %&gt;% mutate(state_name = str_to_lower(abbr2state(`State/Province`))) # US states map information - coordinates used to draw borders states_map &lt;- map_data(&quot;state&quot;) # map that colors state by number of Starbucks starbucks_us_by_state %&gt;% ggplot() + geom_map( map = states_map, aes( map_id = state_name, fill = n ) ) + # This assures the map looks decently nice: expand_limits(x = states_map$long, y = states_map$lat) + theme_map() Now, let’s look more closely at what each piece of the code below is doing. starbucks_us_by_state %&gt;% ggplot() + geom_map( map = states_map, aes( map_id = state_name, fill = n ) ) + expand_limits(x = states_map$long, y = states_map$lat) + theme_map() Choose a Map The map argument tells R at which level to create the map. Really, it tells it how to draw all the borders This is a very special data set. According to the geom_map() documentation, it is a “data frame that contains the map coordinates … It must contain columns x or long, y or lat, and region or id.” We are using the map_data() function to create the map file (see above for more details. You can open the map data, states_map, and see that it adheres to the rules. starbucks_us_by_state %>%&nbsp;&nbsp;ggplot() +&nbsp;&nbsp;geom_map(&nbsp;&nbsp;&nbsp;&nbsp;map = states_map,&nbsp;&nbsp;&nbsp;&nbsp;aes(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;map_id = state_name,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fill = n&nbsp;&nbsp;&nbsp;&nbsp;)&nbsp;&nbsp;) +&nbsp;&nbsp;expand_limits(x = states_map$long, y = states_map$lat) +&nbsp;&nbsp;theme_map() Connect Map ID/Region Variable to Data Being Plotted The map_id inside of aes() is a required aesthetic for the geom_map() geom. It tells R which variable is the region/id variable, in this case the state. It connects the region or id from the map (region variable in states_map dataset, in this example) to the dataset being plotted (state_name in starbucks_us_by_state, in this example). So state_name needs to have the same form as region, which is why we modified the state names in starbucks_us_by_state. starbucks_us_by_state %>%&nbsp;&nbsp;ggplot() +&nbsp;&nbsp;geom_map(&nbsp;&nbsp;&nbsp;&nbsp;map = states_map,&nbsp;&nbsp;&nbsp;&nbsp;aes(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;map_id = state_name,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fill = n&nbsp;&nbsp;&nbsp;&nbsp;)&nbsp;&nbsp;) +&nbsp;&nbsp;expand_limits(x = states_map$long, y = states_map$lat) +&nbsp;&nbsp;theme_map() Use ggplot2 Features We tell it to fill in the states by the variable n, the number of Starbucks in each state. With the geom_map() geom, it will fill in the borders of the regions we defined in the map argument. starbucks_us_by_state %>%&nbsp;&nbsp;ggplot() +&nbsp;&nbsp;geom_map(&nbsp;&nbsp;&nbsp;&nbsp;map = states_map,&nbsp;&nbsp;&nbsp;&nbsp;aes(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;map_id = state_name,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fill = n&nbsp;&nbsp;&nbsp;&nbsp;)&nbsp;&nbsp;) +&nbsp;&nbsp;expand_limits(x = states_map$long, y = states_map$lat) +&nbsp;&nbsp;theme_map() expand_limits() Use expand_limits() to assure that the map covers the entire area it’s supposed to. We put the longitude variable from states_map for the x argument and the latitude variable from states_map for the y argument to assure the map stretches across the entire range of longitudes and latitudes in the map. starbucks_us_by_state %>%&nbsp;&nbsp;ggplot() +&nbsp;&nbsp;geom_map(&nbsp;&nbsp;&nbsp;&nbsp;map = states_map,&nbsp;&nbsp;&nbsp;&nbsp;aes(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;map_id = state_name,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fill = n&nbsp;&nbsp;&nbsp;&nbsp;)&nbsp;&nbsp;) +&nbsp;&nbsp;expand_limits(x = states_map$long, y = states_map$lat) +&nbsp;&nbsp;theme_map() theme_map() This is a personal preference, but theme_map() often makes the map look nicer. starbucks_us_by_state %>%&nbsp;&nbsp;ggplot() +&nbsp;&nbsp;geom_map(&nbsp;&nbsp;&nbsp;&nbsp;map = states_map,&nbsp;&nbsp;&nbsp;&nbsp;aes(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;map_id = state_name,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fill = n&nbsp;&nbsp;&nbsp;&nbsp;)&nbsp;&nbsp;) +&nbsp;&nbsp;expand_limits(x = states_map$long, y = states_map$lat) +&nbsp;&nbsp;theme_map() Add ggplot2 Layers You can add any of the ggplot2 layers on top of this map. In this example, we’ve added MN Starbucks as points, included a title, and changed the legend background (so it doesn’t have one). starbucks_us_by_state %&gt;% ggplot() + geom_map( map = states_map, aes( map_id = state_name, fill = n ) ) + geom_point( data = Starbucks %&gt;% filter(`State/Province` == &quot;MN&quot;), aes(x = Longitude, y = Latitude), size = 0.05, alpha = 0.2, color = &quot;goldenrod&quot; ) + expand_limits(x = states_map$long, y = states_map$lat) + labs(title = &quot;Starbucks in MN&quot;) + theme_map() + theme(legend.background = element_blank()) Resources Prof. Lendway’s demo video ggplot2 documentation Example by Arie Voorman (some things could be out of date since it’s from 2015) Alternative Methods There are plenty of other methods available to make choropleths in R. Let’s demonstrate just three additional methods with data on the 2016 U.S. presidential election results by county: elect &lt;- read.csv(&quot;https://www.macalester.edu/~ajohns24/data/electionDemographics16.csv&quot;) # reformat the FIPS region codes elect &lt;- elect %&gt;% mutate(fips = ifelse(region &lt; 10000, paste(&quot;0&quot;, as.character(region), sep = &quot;&quot;), as.character(region))) # define appropriate (&amp; nicely labeled) breaks elect$brk &lt;- cut(elect$perrep_2016, breaks = seq(0, 100, by = 10), labels = c( &quot;0-9&quot;, &quot;10-19&quot;, &quot;20-29&quot;, &quot;30-39&quot;, &quot;40-49&quot;, &quot;50-59&quot;, &quot;60-69&quot;, &quot;70-79&quot;, &quot;80-89&quot;, &quot;90-100&quot; ), include.lowest = TRUE ) First, we will load a map of the counties in the United States: county_map &lt;- socviz::county_map # from socviz library mapping_data &lt;- elect %&gt;% mutate(id = fips) %&gt;% left_join(county_map, by = &quot;id&quot;) Now here is the map with the method from above, using ggplot + geom_map: ggplot(elect) + geom_map(data = elect, map = county_map, aes(map_id = fips, fill = brk)) + scale_fill_manual(values = rev(brewer.pal(10, &quot;RdBu&quot;)), name = &quot;Percent Republican&quot;) + expand_limits(x = county_map$long, y = county_map$lat) + theme_map() + theme(legend.position = &quot;right&quot;) Alternative 1: ggplot + geom_polygon ggplot(mapping_data, aes(x = long, y = lat, fill = perrep_2016, group = group)) + coord_equal() + geom_polygon(color = NA) + scale_fill_gradientn(name = &quot;Percent Republican&quot;, colours = c(&quot;blue&quot;, &quot;purple&quot;, &quot;red&quot;), values = scales::rescale(seq(0, 100, by = 10))) + theme_map() + theme(legend.position = &quot;right&quot;) Alternative 2: plot_usmap # This function is in the usmap package plot_usmap(data = elect, values = &quot;brk&quot;, color = NA, exclude = &quot;AK&quot;) + scale_fill_manual(values = rev(brewer.pal(10, &quot;RdBu&quot;)), name = &quot;Percent Republican&quot;) + theme(legend.position = &quot;right&quot;) Exercise: Even More with Starbucks The example above did not account for population of each state in the map. In the code below, a new variable is created, starbucks_per_10000, that gives the number of Starbucks per 10,000 people. It is in the starbucks_with_2018_pop_est dataset. Here is a link to the data census_pop_est_2018 &lt;- read_csv(&quot;https://bcheggeseth.github.io/112_fall_2022/data/us_census_2018_state_pop_est.csv&quot;) %&gt;% separate(state, into = c(&quot;dot&quot;, &quot;state&quot;), extra = &quot;merge&quot;) %&gt;% select(-dot) %&gt;% mutate(state = str_to_lower(state)) starbucks_with_2018_pop_est &lt;- starbucks_us_by_state %&gt;% left_join(census_pop_est_2018, by = c(&quot;state_name&quot; = &quot;state&quot;) ) %&gt;% mutate(starbucks_per_10000 = (n / est_pop_2018) * 10000) Exercise 2.2 Create a choropleth state map that shows the number of Starbucks per 10,000 people on a map of the US. Use a new fill color, add points for all Starbucks in the US (except Hawaii and Alaska), add an informative title for the plot, and include a caption that says who created the plot (you!). Make a conclusion about what you observe. Dynamnic Maps with leaflet Leaflet is an open-source JavaScript library for creating maps. It can be used outside of R, but we will only discuss using the leaflet library in R. This library uses a different plotting framework from ggplot2 although it still has a tidyverse feel due to its use of the pipe, %&gt;% and the way it adds layers to the plot, just like in ggplot2. Steps to Create a Map Create a map widget by calling leaflet() and telling it the data to use. Add a base map using addTiles() (the default) or addProviderTiles(). Add layers to the map by using layer functions (e.g. , addMarkers(), addPolygons()) to modify the map widget. Repeat step 3 as desired. Print the map widget to display it. Creating a Map with Markers/Points Below, we create a basic map and add points of interest (the points are a layer on the map). The data are in favorite_stp, created below. The function we will use to create the maps will look for certain variable names for latitude (lat, latitude) and longitude (lng, long, or longitude). If you do not name them one of those things or if the data you are using doesn’t name them that, you need to call out the name explicitly (you’ll see that next). You can use a “two-finger scroll” to zoom in and out. # Brianna&#39;s favorite St. Paul places - Used Google Maps to get coordinates #https://support.google.com/maps/answer/18539?hl=en&amp;co=GENIE.Platform%3DDesktop favorite_stp &lt;- tibble( place = c( &quot;Macalester College&quot;, &quot;Groveland Recreation Center&quot;, &quot;Due Focacceria&quot;, &quot;Shadow Falls Park&quot;, &quot;Mattocks Park&quot;, &quot;Carondelet Fields&quot;, &quot;Pizza Luce&quot;, &quot;Cold Front Ice Cream&quot; ), long = c( -93.1712321, -93.1851310, -93.1775469, -93.1944518, -93.171057, -93.1582673, -93.1524256, -93.156652 ), lat = c( 44.9378965, 44.9351034, 44.9274973, 44.9433359, 44.9284142, 44.9251236, 44.9468848, 44.9266768 ) ) leaflet(data = favorite_stp) %&gt;% # base plot addTiles() %&gt;% # base map - default is openstreet map addMarkers() # Adds markers - knows lat and long from names in data The graph below is the same as above, but the code explicitly specifies latitude and longitude, which you would need to do if those variables had a name not recognized by the function, and adds labels. WARNING: DO NOT FORGET THE ~ BEFORE THE VARIABLE NAMES!!! leaflet(data = favorite_stp) %&gt;% addTiles() %&gt;% addMarkers( lng = ~long, lat = ~lat, label = ~place ) We can change just about everything about our map. The plot below is the same plot as above with some aesthetic changes: We changed the base map with addProviderTiles(). To see all available provider base maps, type providers in the console. To access those maps, use providers$PROVIDERNAME inside the addProviderTiles() function, where PROVIDERNAME is one of those listed providers. When you type provider$ a list should show up that you can click on. We changed the marker type by using addCircles() instead of addMarkers() - Search addControl in the Help or type ?addControl into the console to see what all the arguments mean and how you can change them. All variable arguments are preceded with a tilde, ~. The weight argument tells it how thick to make the lines or points, pixels. The opacity argument is the transparency, like the alpha argument in ggplot2. Colors need to be in “hex” form. We used the col2hex() function from the gplot library to do that. The colors also need to be valid R colors. leaflet(data = favorite_stp) %&gt;% addProviderTiles(providers$Stamen.Watercolor) %&gt;% addCircles( lng = ~long, lat = ~lat, label = ~place, weight = 10, opacity = 1, color = col2hex(&quot;darkblue&quot;) ) The map below is also the “same” as the ones above, but with a new base map and a line to trace a route, which was created with the addPolylines() layer. It traces the locations in the order they are entered in the dataset. leaflet(data = favorite_stp) %&gt;% addProviderTiles(providers$CartoDB.DarkMatter) %&gt;% addCircles( lng = ~long, lat = ~lat, label = ~place, weight = 10, opacity = 1, color = col2hex(&quot;darkred&quot;) ) %&gt;% addPolylines( lng = ~long, lat = ~lat, color = col2hex(&quot;darkred&quot;) ) Choropleth Layers with addPolygons() For making maps with borders (like choropleth maps), the functions can receive the base maps with spatial data a few different ways. In the example here, we use functions from the sf package to get the data in the right form. In the demo video listed under Resources below, a data.frame is translated to an sf object. Hopefully those two sets of instructions fit most of the cases you are interested in. In the code chunk below, the function st_read() downloads the shape file for the counties of North Carolina, which is included in the sf package. # North Carolina births and sids deaths nc &lt;- st_read(system.file(&quot;shape/nc.shp&quot;, package = &quot;sf&quot;), quiet = TRUE ) %&gt;% mutate(sid_per_1000birth_79 = SID79 / BIR79 * 1000) # Compute centroid (center) of each county county_centroid_lat_long &lt;- as_tibble(st_coordinates(st_centroid(nc))) %&gt;% rename( centr_long = X, centr_lat = Y ) ## Warning in st_centroid.sf(nc): ## st_centroid assumes attributes are ## constant over geometries of x # County names and sid_per_1000birth_79 nc_centroid_county &lt;- st_drop_geometry(nc) %&gt;% select(NAME, sid_per_1000birth_79) # All centroid level info nc_centroid &lt;- county_centroid_lat_long %&gt;% bind_cols(nc_centroid_county) The dataset has number of births and number of SIDS cases in each county of North Carolina from 1974-1979 and 1979-1984. We computed a variable called sid_per_1000birth_79 which is the number of SIDS cases per 1000 births in 1979. Below, the the NAMES and geometry variables from the first five rows of the data are printed out. The geometry variable contains information about how to plot the boundaries of the counties. Open the dataset and examine the geometry variable. The leaflet function knows that the geometry variable contains this special information. nc %&gt;% select(NAME, geometry) %&gt;% slice(1:5) ## Simple feature collection with 5 features and 1 field ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -81.74107 ymin: 36.07282 xmax: -75.77316 ymax: 36.58965 ## Geodetic CRS: NAD27 ## NAME ## 1 Ashe ## 2 Alleghany ## 3 Surry ## 4 Currituck ## 5 Northampton ## geometry ## 1 MULTIPOLYGON (((-81.47276 3... ## 2 MULTIPOLYGON (((-81.23989 3... ## 3 MULTIPOLYGON (((-80.45634 3... ## 4 MULTIPOLYGON (((-76.00897 3... ## 5 MULTIPOLYGON (((-77.21767 3... To learn more about the data type nc into the Help menu or ?nc into the console. This plot puts the map with North Carolina county borders on top of the Open Street Map. This map isn’t that interesting by itself. leaflet(nc) %&gt;% addTiles() %&gt;% addPolygons() ## Warning: sf layer has inconsistent datum (+proj=longlat +datum=NAD27 +no_defs). ## Need &#39;+proj=longlat +datum=WGS84&#39; Now, let’s use some of the data to enhance the graph by creating a choropleth map where we color the counties by sid_per_1000birth_79. In ggplot(), we can map a variable to color or fill inside the aesthetic, but in the leaflet functions we cannot do this. Instead, we need to create a variable of hex color names that tells it how to color or fill. Thankfully, there are functions that help us do that! Let’s walk through the detail of how we created the graph below. # creates a function that can be used to map a variable to # the color palette using viridis pal &lt;- colorNumeric(&quot;viridis&quot;, domain = nc$sid_per_1000birth_79 ) leaflet(nc) %&gt;% addTiles() %&gt;% addPolygons( fillColor = ~ pal(sid_per_1000birth_79), # fills according to that variable fillOpacity = 0.7 ) # like alpha in ggplot ## Warning: sf layer has inconsistent datum (+proj=longlat +datum=NAD27 +no_defs). ## Need &#39;+proj=longlat +datum=WGS84&#39; The colorNumeric() function returns a function that maps a variable’s values to colors in the given palette, in this case “viridis”. So, pal() is a function. We can then use that function inside addPolygons(). If we apply the function to the sid_per_1000birth_79 variable, it returns a variable of hex colors and the variable of colors is used to fill the counties. Below we print out what happens when pal() is applied to sid_per_1000birth_79. We can see that it returns hex colors. So, the variable in the fillColor argument inside addPolygons() above, is a variable of hex color names. head(pal(nc$sid_per_1000birth_79)) ## [1] &quot;#440154&quot; &quot;#C0DF25&quot; &quot;#38588C&quot; ## [4] &quot;#2A778E&quot; &quot;#34618D&quot; &quot;#26828E&quot; Again, this is different from ggplot(), where we could map a variable to color or fill and it would do the translating of variable to color scale for us. In the leaflet functions, we have to explicitly provide the colors in a variable. The colorNumeric() command helps you do that. colorBin(), colorQuantile(), and colorFactor() are other functions you might need to use depending on the type of variable you are trying to map to colors. There are many customizeable options in leaflet, much like ggplot(). Here is a commented set of code to point out some useful functions and arguments: # creates a function that can be used to map a variable to # the color palette using viridis pal &lt;- colorNumeric(&quot;viridis&quot;, domain = nc$sid_per_1000birth_79 ) leaflet(nc) %&gt;% addTiles() %&gt;% addPolygons( # skips drawing the borders: stroke = FALSE, # fills according to variable of hex colors: fillColor = ~ pal(sid_per_1000birth_79), # changes transparency, like alpha in ggplot fillOpacity = 0.7, # how much to simplify the plot when zooming: smoothFactor = 0.5, # changes what happens to the shape when we mouse over it highlight = highlightOptions( weight = 5, color = &quot;black&quot;, fillOpacity = 0.9, bringToFront = FALSE ) ) %&gt;% addCircles( data = nc_centroid, lng = ~centr_long, lat = ~centr_lat, # label that appears when you click on the marker, # in this case county name and sid_per_1000birth_79 # rounded to the 2nd decimal popup = ~ paste(NAME, &quot;: &quot;, round(sid_per_1000birth_79, 2), sep = &quot;&quot; ), radius = 2 ) %&gt;% # Add a legend addLegend( pal = pal, values = ~sid_per_1000birth_79, opacity = 0.5, title = NULL, position = &quot;bottomright&quot; ) ## Warning: sf layer has inconsistent datum (+proj=longlat +datum=NAD27 +no_defs). ## Need &#39;+proj=longlat +datum=WGS84&#39; Resources Prof. Lendway’s introductory video Prof. Lendway’s demo video Detailed leaflet documenation (with examples) leaflet cheat sheet Provider map previews Tutorial by Andrew Ba Tran, investigative data reporter at Washington Post Exercise: Favorite Places Exercise 2.3 In this exercise, you are going to create a single map of some of your favorite places! The end result will be one map. Create a data set using the tibble() function that has 10-15 rows of your favorite places. The columns will be the name of the location, the latitude, the longitude, and a column that indicates if it is in your top 3 favorite locations or not. For an example of how to use tibble(), look at the favorite_stp that is created manually above. Create a map that uses circles to indicate your favorite places. Label them with the name of the place. Choose the base map you like best. Color your 3 favorite places differently than the ones that are not in your top 3. Add a legend that explains what the colors mean. If there are other variables you want to add that could enhance your plot, do that now. You could also connect all your locations together with a line in a meaningful way (you may need to order them differently in the original data). "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
